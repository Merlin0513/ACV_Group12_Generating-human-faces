{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KR-n0B7YiL2U"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from tensorflow.python.data.experimental import AUTOTUNE\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIWo9NUa5Iz6",
    "outputId": "f0d599c7-8974-432e-a4a7-bc14bd99534c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training the model, first run the last cell of the notebook, which contains classes and methods used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0X77owysjrUV"
   },
   "outputs": [],
   "source": [
    "# Location of model weights (created at the first time of training)\n",
    "weights_dir = '/content/drive/MyDrive/weights/srgan'\n",
    "weights_file = lambda filename: os.path.join(weights_dir, filename)\n",
    "\n",
    "os.makedirs(weights_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hnATfx1zvKb1",
    "outputId": "3d8bdbcb-99f6-42b6-facb-5502e53e4f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip\n",
      "246914039/246914039 [==============================] - 12s 0us/step\n",
      "Caching decoded images in .div2k/caches/DIV2K_train_LR_bicubic_X4.cache ...\n",
      "Cached decoded images in .div2k/caches/DIV2K_train_LR_bicubic_X4.cache.\n",
      "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
      "3530603713/3530603713 [==============================] - 132s 0us/step\n",
      "Caching decoded images in .div2k/caches/DIV2K_train_HR.cache ...\n",
      "Cached decoded images in .div2k/caches/DIV2K_train_HR.cache.\n",
      "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_LR_bicubic_X4.zip\n",
      "31505881/31505881 [==============================] - 2s 0us/step\n",
      "Caching decoded images in .div2k/caches/DIV2K_valid_LR_bicubic_X4.cache ...\n",
      "Cached decoded images in .div2k/caches/DIV2K_valid_LR_bicubic_X4.cache.\n",
      "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
      "448993893/448993893 [==============================] - 36s 0us/step\n",
      "Caching decoded images in .div2k/caches/DIV2K_valid_HR.cache ...\n",
      "Cached decoded images in .div2k/caches/DIV2K_valid_HR.cache.\n"
     ]
    }
   ],
   "source": [
    "## Training and Validation data\n",
    "div2k_train = DIV2K(scale=4, subset='train', downgrade='bicubic')\n",
    "div2k_valid = DIV2K(scale=4, subset='valid', downgrade='bicubic')\n",
    "\n",
    "train_ds = div2k_train.dataset(batch_size=16, random_transform=True)\n",
    "valid_ds = div2k_valid.dataset(batch_size=16, random_transform=True, repeat_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZMe5G1C4FH3",
    "outputId": "d88999ea-2eae-40d9-a1e7-adc2b4941a0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/100000: loss = 578.444, PSNR = 22.663849 (83.41s)\n",
      "2000/100000: loss = 275.995, PSNR = 25.763975 (44.51s)\n",
      "3000/100000: loss = 244.645, PSNR = 25.533216 (44.19s)\n",
      "4000/100000: loss = 227.027, PSNR = 31.288925 (43.99s)\n",
      "5000/100000: loss = 215.288, PSNR = 26.042233 (43.79s)\n",
      "6000/100000: loss = 210.440, PSNR = 24.551090 (43.90s)\n",
      "7000/100000: loss = 204.814, PSNR = 27.085978 (45.44s)\n",
      "8000/100000: loss = 202.107, PSNR = 27.886385 (46.27s)\n",
      "9000/100000: loss = 196.296, PSNR = 26.405333 (45.64s)\n",
      "10000/100000: loss = 193.728, PSNR = 27.875452 (44.98s)\n",
      "11000/100000: loss = 189.567, PSNR = 24.445988 (44.69s)\n",
      "12000/100000: loss = 189.909, PSNR = 29.778955 (44.66s)\n",
      "13000/100000: loss = 188.014, PSNR = 31.340637 (44.74s)\n",
      "14000/100000: loss = 189.040, PSNR = 29.508976 (43.77s)\n",
      "15000/100000: loss = 186.263, PSNR = 28.754232 (43.73s)\n",
      "16000/100000: loss = 183.244, PSNR = 27.994638 (43.64s)\n",
      "17000/100000: loss = 181.239, PSNR = 26.083151 (43.67s)\n",
      "18000/100000: loss = 183.494, PSNR = 29.066410 (43.78s)\n",
      "19000/100000: loss = 184.361, PSNR = 29.211096 (43.67s)\n",
      "20000/100000: loss = 180.690, PSNR = 29.778139 (43.71s)\n",
      "21000/100000: loss = 179.010, PSNR = 27.731915 (44.00s)\n",
      "22000/100000: loss = 183.544, PSNR = 29.915506 (43.86s)\n",
      "23000/100000: loss = 176.348, PSNR = 26.246176 (43.64s)\n",
      "24000/100000: loss = 180.429, PSNR = 26.654922 (43.43s)\n",
      "25000/100000: loss = 176.366, PSNR = 29.284878 (43.47s)\n",
      "26000/100000: loss = 176.575, PSNR = 27.008877 (43.47s)\n",
      "27000/100000: loss = 174.544, PSNR = 30.890411 (44.15s)\n",
      "28000/100000: loss = 177.186, PSNR = 28.329433 (43.95s)\n",
      "29000/100000: loss = 174.031, PSNR = 30.563494 (43.63s)\n",
      "30000/100000: loss = 173.547, PSNR = 28.367580 (43.65s)\n",
      "31000/100000: loss = 174.625, PSNR = 29.700958 (43.80s)\n",
      "32000/100000: loss = 175.162, PSNR = 29.558096 (43.79s)\n",
      "33000/100000: loss = 172.429, PSNR = 30.486389 (43.90s)\n",
      "34000/100000: loss = 169.233, PSNR = 25.073103 (43.72s)\n",
      "35000/100000: loss = 170.011, PSNR = 24.036402 (43.74s)\n",
      "36000/100000: loss = 174.032, PSNR = 30.541214 (43.72s)\n",
      "37000/100000: loss = 169.365, PSNR = 29.836426 (43.61s)\n",
      "38000/100000: loss = 173.382, PSNR = 34.570328 (43.81s)\n",
      "39000/100000: loss = 170.427, PSNR = 29.001806 (43.77s)\n",
      "40000/100000: loss = 173.749, PSNR = 28.801592 (43.66s)\n",
      "41000/100000: loss = 172.013, PSNR = 28.497379 (43.64s)\n",
      "42000/100000: loss = 171.028, PSNR = 29.037386 (43.55s)\n",
      "43000/100000: loss = 169.655, PSNR = 32.194538 (43.76s)\n",
      "44000/100000: loss = 169.379, PSNR = 30.279114 (43.62s)\n",
      "45000/100000: loss = 171.586, PSNR = 28.180830 (43.63s)\n",
      "45000/100000: loss = 171.586, PSNR = 28.180830 (43.63s)\n",
      "46000/100000: loss = 174.161, PSNR = 26.220413 (43.57s)\n",
      "46000/100000: loss = 174.161, PSNR = 26.220413 (43.57s)\n",
      "47000/100000: loss = 168.670, PSNR = 26.776136 (43.69s)\n",
      "47000/100000: loss = 168.670, PSNR = 26.776136 (43.69s)\n",
      "48000/100000: loss = 170.128, PSNR = 29.396130 (43.70s)\n",
      "48000/100000: loss = 170.128, PSNR = 29.396130 (43.70s)\n",
      "49000/100000: loss = 166.137, PSNR = 28.911686 (43.74s)\n",
      "49000/100000: loss = 166.137, PSNR = 28.911686 (43.74s)\n",
      "50000/100000: loss = 168.650, PSNR = 32.523914 (43.62s)\n",
      "50000/100000: loss = 168.650, PSNR = 32.523914 (43.62s)\n",
      "51000/100000: loss = 167.137, PSNR = 27.833788 (43.58s)\n",
      "51000/100000: loss = 167.137, PSNR = 27.833788 (43.58s)\n",
      "52000/100000: loss = 169.955, PSNR = 28.925079 (43.70s)\n",
      "52000/100000: loss = 169.955, PSNR = 28.925079 (43.70s)\n",
      "53000/100000: loss = 167.789, PSNR = 25.125818 (43.57s)\n",
      "53000/100000: loss = 167.789, PSNR = 25.125818 (43.57s)\n",
      "54000/100000: loss = 169.339, PSNR = 26.919353 (43.54s)\n",
      "54000/100000: loss = 169.339, PSNR = 26.919353 (43.54s)\n",
      "55000/100000: loss = 168.462, PSNR = 31.857359 (43.85s)\n",
      "55000/100000: loss = 168.462, PSNR = 31.857359 (43.85s)\n",
      "56000/100000: loss = 168.220, PSNR = 28.162109 (43.54s)\n",
      "56000/100000: loss = 168.220, PSNR = 28.162109 (43.54s)\n",
      "57000/100000: loss = 166.767, PSNR = 27.441620 (43.42s)\n",
      "57000/100000: loss = 166.767, PSNR = 27.441620 (43.42s)\n",
      "58000/100000: loss = 168.241, PSNR = 27.792908 (44.66s)\n",
      "58000/100000: loss = 168.241, PSNR = 27.792908 (44.66s)\n",
      "59000/100000: loss = 167.710, PSNR = 30.127384 (43.54s)\n",
      "59000/100000: loss = 167.710, PSNR = 30.127384 (43.54s)\n",
      "60000/100000: loss = 168.913, PSNR = 32.344662 (43.61s)\n",
      "60000/100000: loss = 168.913, PSNR = 32.344662 (43.61s)\n",
      "61000/100000: loss = 168.802, PSNR = 26.625820 (43.71s)\n",
      "61000/100000: loss = 168.802, PSNR = 26.625820 (43.71s)\n",
      "62000/100000: loss = 166.987, PSNR = 33.564484 (43.52s)\n",
      "62000/100000: loss = 166.987, PSNR = 33.564484 (43.52s)\n",
      "63000/100000: loss = 165.580, PSNR = 30.085514 (43.51s)\n",
      "63000/100000: loss = 165.580, PSNR = 30.085514 (43.51s)\n",
      "64000/100000: loss = 167.207, PSNR = 31.245546 (43.52s)\n",
      "64000/100000: loss = 167.207, PSNR = 31.245546 (43.52s)\n",
      "65000/100000: loss = 166.163, PSNR = 34.489464 (43.59s)\n",
      "65000/100000: loss = 166.163, PSNR = 34.489464 (43.59s)\n",
      "66000/100000: loss = 165.720, PSNR = 32.985352 (45.62s)\n",
      "66000/100000: loss = 165.720, PSNR = 32.985352 (45.62s)\n",
      "67000/100000: loss = 167.519, PSNR = 29.100891 (45.02s)\n",
      "67000/100000: loss = 167.519, PSNR = 29.100891 (45.02s)\n",
      "68000/100000: loss = 165.796, PSNR = 31.865900 (44.47s)\n",
      "68000/100000: loss = 165.796, PSNR = 31.865900 (44.47s)\n",
      "69000/100000: loss = 166.209, PSNR = 25.279554 (44.66s)\n",
      "69000/100000: loss = 166.209, PSNR = 25.279554 (44.66s)\n",
      "70000/100000: loss = 163.554, PSNR = 28.378298 (44.67s)\n",
      "70000/100000: loss = 163.554, PSNR = 28.378298 (44.67s)\n",
      "71000/100000: loss = 166.169, PSNR = 31.659229 (45.11s)\n",
      "71000/100000: loss = 166.169, PSNR = 31.659229 (45.11s)\n",
      "72000/100000: loss = 165.335, PSNR = 27.249542 (43.78s)\n",
      "72000/100000: loss = 165.335, PSNR = 27.249542 (43.78s)\n",
      "73000/100000: loss = 164.869, PSNR = 27.512936 (43.60s)\n",
      "73000/100000: loss = 164.869, PSNR = 27.512936 (43.60s)\n",
      "74000/100000: loss = 164.294, PSNR = 28.186008 (43.60s)\n",
      "74000/100000: loss = 164.294, PSNR = 28.186008 (43.60s)\n",
      "75000/100000: loss = 163.324, PSNR = 29.310793 (43.57s)\n",
      "75000/100000: loss = 163.324, PSNR = 29.310793 (43.57s)\n",
      "76000/100000: loss = 163.650, PSNR = 30.733255 (43.44s)\n",
      "76000/100000: loss = 163.650, PSNR = 30.733255 (43.44s)\n",
      "77000/100000: loss = 167.235, PSNR = 28.032959 (43.49s)\n",
      "77000/100000: loss = 167.235, PSNR = 28.032959 (43.49s)\n",
      "78000/100000: loss = 166.226, PSNR = 32.248932 (43.59s)\n",
      "78000/100000: loss = 166.226, PSNR = 32.248932 (43.59s)\n",
      "79000/100000: loss = 163.845, PSNR = 32.475773 (43.47s)\n",
      "79000/100000: loss = 163.845, PSNR = 32.475773 (43.47s)\n",
      "80000/100000: loss = 165.885, PSNR = 30.695505 (43.46s)\n",
      "80000/100000: loss = 165.885, PSNR = 30.695505 (43.46s)\n",
      "81000/100000: loss = 163.750, PSNR = 32.309425 (43.55s)\n",
      "81000/100000: loss = 163.750, PSNR = 32.309425 (43.55s)\n",
      "82000/100000: loss = 165.677, PSNR = 28.681580 (43.48s)\n",
      "82000/100000: loss = 165.677, PSNR = 28.681580 (43.48s)\n",
      "83000/100000: loss = 165.203, PSNR = 28.401724 (43.57s)\n",
      "83000/100000: loss = 165.203, PSNR = 28.401724 (43.57s)\n",
      "84000/100000: loss = 164.099, PSNR = 31.605282 (43.76s)\n",
      "84000/100000: loss = 164.099, PSNR = 31.605282 (43.76s)\n",
      "85000/100000: loss = 162.532, PSNR = 31.836582 (43.57s)\n",
      "85000/100000: loss = 162.532, PSNR = 31.836582 (43.57s)\n",
      "86000/100000: loss = 168.579, PSNR = 28.743250 (43.49s)\n",
      "86000/100000: loss = 168.579, PSNR = 28.743250 (43.49s)\n",
      "87000/100000: loss = 163.477, PSNR = 33.266228 (43.59s)\n",
      "87000/100000: loss = 163.477, PSNR = 33.266228 (43.59s)\n",
      "88000/100000: loss = 164.109, PSNR = 30.499935 (43.58s)\n",
      "88000/100000: loss = 164.109, PSNR = 30.499935 (43.58s)\n",
      "89000/100000: loss = 160.255, PSNR = 28.845690 (43.40s)\n",
      "89000/100000: loss = 160.255, PSNR = 28.845690 (43.40s)\n",
      "90000/100000: loss = 162.000, PSNR = 30.589796 (43.50s)\n",
      "90000/100000: loss = 162.000, PSNR = 30.589796 (43.50s)\n",
      "91000/100000: loss = 164.410, PSNR = 31.039951 (43.46s)\n",
      "91000/100000: loss = 164.410, PSNR = 31.039951 (43.46s)\n",
      "92000/100000: loss = 162.893, PSNR = 28.301081 (43.47s)\n",
      "92000/100000: loss = 162.893, PSNR = 28.301081 (43.47s)\n",
      "93000/100000: loss = 164.443, PSNR = 28.088793 (44.30s)\n",
      "93000/100000: loss = 164.443, PSNR = 28.088793 (44.30s)\n",
      "94000/100000: loss = 161.641, PSNR = 32.134403 (43.89s)\n",
      "94000/100000: loss = 161.641, PSNR = 32.134403 (43.89s)\n",
      "95000/100000: loss = 161.670, PSNR = 28.463392 (43.51s)\n",
      "95000/100000: loss = 161.670, PSNR = 28.463392 (43.51s)\n",
      "96000/100000: loss = 160.237, PSNR = 27.404985 (43.57s)\n",
      "96000/100000: loss = 160.237, PSNR = 27.404985 (43.57s)\n",
      "97000/100000: loss = 166.436, PSNR = 28.990286 (43.53s)\n",
      "97000/100000: loss = 166.436, PSNR = 28.990286 (43.53s)\n",
      "98000/100000: loss = 161.115, PSNR = 32.388832 (43.55s)\n",
      "98000/100000: loss = 161.115, PSNR = 32.388832 (43.55s)\n",
      "99000/100000: loss = 165.152, PSNR = 26.866648 (43.63s)\n",
      "99000/100000: loss = 165.152, PSNR = 26.866648 (43.63s)\n",
      "100000/100000: loss = 164.960, PSNR = 32.875340 (43.49s)\n",
      "100000/100000: loss = 164.960, PSNR = 32.875340 (43.49s)\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 0s 0us/step\n",
      "80134624/80134624 [==============================] - 0s 0us/step\n",
      "50/20000, perceptual loss = 0.1778, discriminator loss = 0.7867\n",
      "50/20000, perceptual loss = 0.1778, discriminator loss = 0.7867\n",
      "100/20000, perceptual loss = 0.1779, discriminator loss = 0.2528\n",
      "100/20000, perceptual loss = 0.1779, discriminator loss = 0.2528\n",
      "150/20000, perceptual loss = 0.1756, discriminator loss = 0.3228\n",
      "150/20000, perceptual loss = 0.1756, discriminator loss = 0.3228\n",
      "200/20000, perceptual loss = 0.1727, discriminator loss = 0.3986\n",
      "200/20000, perceptual loss = 0.1727, discriminator loss = 0.3986\n",
      "250/20000, perceptual loss = 0.1802, discriminator loss = 0.2815\n",
      "250/20000, perceptual loss = 0.1802, discriminator loss = 0.2815\n",
      "300/20000, perceptual loss = 0.1716, discriminator loss = 0.1678\n",
      "300/20000, perceptual loss = 0.1716, discriminator loss = 0.1678\n",
      "350/20000, perceptual loss = 0.1780, discriminator loss = 0.3600\n",
      "350/20000, perceptual loss = 0.1780, discriminator loss = 0.3600\n",
      "400/20000, perceptual loss = 0.1858, discriminator loss = 0.3490\n",
      "400/20000, perceptual loss = 0.1858, discriminator loss = 0.3490\n",
      "450/20000, perceptual loss = 0.1767, discriminator loss = 0.3877\n",
      "450/20000, perceptual loss = 0.1767, discriminator loss = 0.3877\n",
      "500/20000, perceptual loss = 0.1732, discriminator loss = 0.2726\n",
      "500/20000, perceptual loss = 0.1732, discriminator loss = 0.2726\n",
      "550/20000, perceptual loss = 0.1775, discriminator loss = 0.5299\n",
      "550/20000, perceptual loss = 0.1775, discriminator loss = 0.5299\n",
      "600/20000, perceptual loss = 0.1780, discriminator loss = 0.5952\n",
      "600/20000, perceptual loss = 0.1780, discriminator loss = 0.5952\n",
      "650/20000, perceptual loss = 0.1703, discriminator loss = 0.4764\n",
      "650/20000, perceptual loss = 0.1703, discriminator loss = 0.4764\n",
      "700/20000, perceptual loss = 0.1739, discriminator loss = 0.1680\n",
      "700/20000, perceptual loss = 0.1739, discriminator loss = 0.1680\n",
      "750/20000, perceptual loss = 0.1727, discriminator loss = 1.0210\n",
      "750/20000, perceptual loss = 0.1727, discriminator loss = 1.0210\n",
      "800/20000, perceptual loss = 0.1742, discriminator loss = 0.6292\n",
      "800/20000, perceptual loss = 0.1742, discriminator loss = 0.6292\n",
      "850/20000, perceptual loss = 0.1791, discriminator loss = 0.3855\n",
      "850/20000, perceptual loss = 0.1791, discriminator loss = 0.3855\n",
      "900/20000, perceptual loss = 0.1789, discriminator loss = 0.8207\n",
      "900/20000, perceptual loss = 0.1789, discriminator loss = 0.8207\n",
      "950/20000, perceptual loss = 0.1763, discriminator loss = 0.5978\n",
      "950/20000, perceptual loss = 0.1763, discriminator loss = 0.5978\n",
      "1000/20000, perceptual loss = 0.1758, discriminator loss = 0.4522\n",
      "1000/20000, perceptual loss = 0.1758, discriminator loss = 0.4522\n",
      "1050/20000, perceptual loss = 0.1822, discriminator loss = 0.2217\n",
      "1050/20000, perceptual loss = 0.1822, discriminator loss = 0.2217\n",
      "1100/20000, perceptual loss = 0.1733, discriminator loss = 0.7051\n",
      "1100/20000, perceptual loss = 0.1733, discriminator loss = 0.7051\n",
      "1150/20000, perceptual loss = 0.1840, discriminator loss = 0.4905\n",
      "1150/20000, perceptual loss = 0.1840, discriminator loss = 0.4905\n",
      "1200/20000, perceptual loss = 0.1834, discriminator loss = 0.6825\n",
      "1200/20000, perceptual loss = 0.1834, discriminator loss = 0.6825\n",
      "1250/20000, perceptual loss = 0.1693, discriminator loss = 1.0207\n",
      "1250/20000, perceptual loss = 0.1693, discriminator loss = 1.0207\n",
      "1300/20000, perceptual loss = 0.1757, discriminator loss = 0.6893\n",
      "1300/20000, perceptual loss = 0.1757, discriminator loss = 0.6893\n",
      "1350/20000, perceptual loss = 0.1793, discriminator loss = 0.5288\n",
      "1350/20000, perceptual loss = 0.1793, discriminator loss = 0.5288\n",
      "1400/20000, perceptual loss = 0.1723, discriminator loss = 0.5059\n",
      "1400/20000, perceptual loss = 0.1723, discriminator loss = 0.5059\n",
      "1450/20000, perceptual loss = 0.1801, discriminator loss = 0.3481\n",
      "1450/20000, perceptual loss = 0.1801, discriminator loss = 0.3481\n",
      "1500/20000, perceptual loss = 0.1863, discriminator loss = 0.4502\n",
      "1500/20000, perceptual loss = 0.1863, discriminator loss = 0.4502\n",
      "1550/20000, perceptual loss = 0.1761, discriminator loss = 0.2896\n",
      "1550/20000, perceptual loss = 0.1761, discriminator loss = 0.2896\n",
      "1600/20000, perceptual loss = 0.1728, discriminator loss = 0.6150\n",
      "1600/20000, perceptual loss = 0.1728, discriminator loss = 0.6150\n",
      "1650/20000, perceptual loss = 0.1772, discriminator loss = 0.3426\n",
      "1650/20000, perceptual loss = 0.1772, discriminator loss = 0.3426\n",
      "1700/20000, perceptual loss = 0.1836, discriminator loss = 2.2150\n",
      "1700/20000, perceptual loss = 0.1836, discriminator loss = 2.2150\n",
      "1750/20000, perceptual loss = 0.1773, discriminator loss = 0.6308\n",
      "1750/20000, perceptual loss = 0.1773, discriminator loss = 0.6308\n",
      "1800/20000, perceptual loss = 0.1710, discriminator loss = 0.9584\n",
      "1800/20000, perceptual loss = 0.1710, discriminator loss = 0.9584\n",
      "1850/20000, perceptual loss = 0.1762, discriminator loss = 0.8243\n",
      "1850/20000, perceptual loss = 0.1762, discriminator loss = 0.8243\n",
      "1900/20000, perceptual loss = 0.1758, discriminator loss = 0.4241\n",
      "1900/20000, perceptual loss = 0.1758, discriminator loss = 0.4241\n",
      "1950/20000, perceptual loss = 0.1837, discriminator loss = 0.5897\n",
      "1950/20000, perceptual loss = 0.1837, discriminator loss = 0.5897\n",
      "2000/20000, perceptual loss = 0.1807, discriminator loss = 0.5471\n",
      "2000/20000, perceptual loss = 0.1807, discriminator loss = 0.5471\n",
      "2050/20000, perceptual loss = 0.1899, discriminator loss = 1.2501\n",
      "2050/20000, perceptual loss = 0.1899, discriminator loss = 1.2501\n",
      "2100/20000, perceptual loss = 0.1874, discriminator loss = 0.4318\n",
      "2100/20000, perceptual loss = 0.1874, discriminator loss = 0.4318\n",
      "2150/20000, perceptual loss = 0.1675, discriminator loss = 0.5126\n",
      "2150/20000, perceptual loss = 0.1675, discriminator loss = 0.5126\n",
      "2200/20000, perceptual loss = 0.1728, discriminator loss = 0.8454\n",
      "2200/20000, perceptual loss = 0.1728, discriminator loss = 0.8454\n",
      "2250/20000, perceptual loss = 0.1799, discriminator loss = 0.5199\n",
      "2250/20000, perceptual loss = 0.1799, discriminator loss = 0.5199\n",
      "2300/20000, perceptual loss = 0.1734, discriminator loss = 0.4425\n",
      "2300/20000, perceptual loss = 0.1734, discriminator loss = 0.4425\n",
      "2350/20000, perceptual loss = 0.1779, discriminator loss = 0.4540\n",
      "2350/20000, perceptual loss = 0.1779, discriminator loss = 0.4540\n",
      "2400/20000, perceptual loss = 0.1796, discriminator loss = 0.2459\n",
      "2400/20000, perceptual loss = 0.1796, discriminator loss = 0.2459\n",
      "2450/20000, perceptual loss = 0.1707, discriminator loss = 1.0030\n",
      "2450/20000, perceptual loss = 0.1707, discriminator loss = 1.0030\n",
      "2500/20000, perceptual loss = 0.1726, discriminator loss = 0.3130\n",
      "2500/20000, perceptual loss = 0.1726, discriminator loss = 0.3130\n",
      "2550/20000, perceptual loss = 0.1797, discriminator loss = 0.8508\n",
      "2550/20000, perceptual loss = 0.1797, discriminator loss = 0.8508\n",
      "2600/20000, perceptual loss = 0.1700, discriminator loss = 0.5957\n",
      "2600/20000, perceptual loss = 0.1700, discriminator loss = 0.5957\n",
      "2650/20000, perceptual loss = 0.1767, discriminator loss = 0.5973\n",
      "2650/20000, perceptual loss = 0.1767, discriminator loss = 0.5973\n",
      "2700/20000, perceptual loss = 0.1811, discriminator loss = 0.2653\n",
      "2700/20000, perceptual loss = 0.1811, discriminator loss = 0.2653\n",
      "2750/20000, perceptual loss = 0.1719, discriminator loss = 0.6307\n",
      "2750/20000, perceptual loss = 0.1719, discriminator loss = 0.6307\n",
      "2800/20000, perceptual loss = 0.1838, discriminator loss = 0.2267\n",
      "2800/20000, perceptual loss = 0.1838, discriminator loss = 0.2267\n",
      "2850/20000, perceptual loss = 0.1765, discriminator loss = 0.7875\n",
      "2850/20000, perceptual loss = 0.1765, discriminator loss = 0.7875\n",
      "2900/20000, perceptual loss = 0.1674, discriminator loss = 0.5484\n",
      "2900/20000, perceptual loss = 0.1674, discriminator loss = 0.5484\n",
      "2950/20000, perceptual loss = 0.1695, discriminator loss = 1.2240\n",
      "2950/20000, perceptual loss = 0.1695, discriminator loss = 1.2240\n",
      "3000/20000, perceptual loss = 0.1703, discriminator loss = 0.6465\n",
      "3000/20000, perceptual loss = 0.1703, discriminator loss = 0.6465\n",
      "3050/20000, perceptual loss = 0.1810, discriminator loss = 0.3537\n",
      "3050/20000, perceptual loss = 0.1810, discriminator loss = 0.3537\n",
      "3100/20000, perceptual loss = 0.1791, discriminator loss = 0.7086\n",
      "3100/20000, perceptual loss = 0.1791, discriminator loss = 0.7086\n",
      "3150/20000, perceptual loss = 0.1710, discriminator loss = 0.5166\n",
      "3150/20000, perceptual loss = 0.1710, discriminator loss = 0.5166\n",
      "3200/20000, perceptual loss = 0.1658, discriminator loss = 0.4368\n",
      "3200/20000, perceptual loss = 0.1658, discriminator loss = 0.4368\n",
      "3250/20000, perceptual loss = 0.1796, discriminator loss = 1.9426\n",
      "3250/20000, perceptual loss = 0.1796, discriminator loss = 1.9426\n",
      "3300/20000, perceptual loss = 0.1874, discriminator loss = 0.6181\n",
      "3300/20000, perceptual loss = 0.1874, discriminator loss = 0.6181\n",
      "3350/20000, perceptual loss = 0.1805, discriminator loss = 0.8238\n",
      "3350/20000, perceptual loss = 0.1805, discriminator loss = 0.8238\n",
      "3400/20000, perceptual loss = 0.1699, discriminator loss = 0.7152\n",
      "3400/20000, perceptual loss = 0.1699, discriminator loss = 0.7152\n",
      "3450/20000, perceptual loss = 0.1832, discriminator loss = 0.6591\n",
      "3450/20000, perceptual loss = 0.1832, discriminator loss = 0.6591\n",
      "3500/20000, perceptual loss = 0.1713, discriminator loss = 0.6364\n",
      "3500/20000, perceptual loss = 0.1713, discriminator loss = 0.6364\n",
      "3550/20000, perceptual loss = 0.1736, discriminator loss = 0.6090\n",
      "3550/20000, perceptual loss = 0.1736, discriminator loss = 0.6090\n",
      "3600/20000, perceptual loss = 0.1701, discriminator loss = 1.1905\n",
      "3600/20000, perceptual loss = 0.1701, discriminator loss = 1.1905\n",
      "3650/20000, perceptual loss = 0.1703, discriminator loss = 1.5282\n",
      "3650/20000, perceptual loss = 0.1703, discriminator loss = 1.5282\n",
      "3700/20000, perceptual loss = 0.1754, discriminator loss = 0.6568\n",
      "3700/20000, perceptual loss = 0.1754, discriminator loss = 0.6568\n",
      "3750/20000, perceptual loss = 0.1706, discriminator loss = 0.8225\n",
      "3750/20000, perceptual loss = 0.1706, discriminator loss = 0.8225\n",
      "3800/20000, perceptual loss = 0.1989, discriminator loss = 0.6726\n",
      "3800/20000, perceptual loss = 0.1989, discriminator loss = 0.6726\n",
      "3850/20000, perceptual loss = 0.1729, discriminator loss = 0.8284\n",
      "3850/20000, perceptual loss = 0.1729, discriminator loss = 0.8284\n",
      "3900/20000, perceptual loss = 0.1652, discriminator loss = 0.4840\n",
      "3900/20000, perceptual loss = 0.1652, discriminator loss = 0.4840\n",
      "3950/20000, perceptual loss = 0.1829, discriminator loss = 0.4912\n",
      "3950/20000, perceptual loss = 0.1829, discriminator loss = 0.4912\n",
      "4000/20000, perceptual loss = 0.1673, discriminator loss = 0.9498\n",
      "4000/20000, perceptual loss = 0.1673, discriminator loss = 0.9498\n",
      "4050/20000, perceptual loss = 0.1748, discriminator loss = 0.5758\n",
      "4050/20000, perceptual loss = 0.1748, discriminator loss = 0.5758\n",
      "4100/20000, perceptual loss = 0.1755, discriminator loss = 0.4434\n",
      "4100/20000, perceptual loss = 0.1755, discriminator loss = 0.4434\n",
      "4150/20000, perceptual loss = 0.1692, discriminator loss = 0.4848\n",
      "4150/20000, perceptual loss = 0.1692, discriminator loss = 0.4848\n",
      "4200/20000, perceptual loss = 0.1785, discriminator loss = 1.2445\n",
      "4200/20000, perceptual loss = 0.1785, discriminator loss = 1.2445\n",
      "4250/20000, perceptual loss = 0.1833, discriminator loss = 0.7360\n",
      "4250/20000, perceptual loss = 0.1833, discriminator loss = 0.7360\n",
      "4300/20000, perceptual loss = 0.1712, discriminator loss = 0.3332\n",
      "4300/20000, perceptual loss = 0.1712, discriminator loss = 0.3332\n",
      "4350/20000, perceptual loss = 0.1694, discriminator loss = 0.9464\n",
      "4350/20000, perceptual loss = 0.1694, discriminator loss = 0.9464\n",
      "4400/20000, perceptual loss = 0.1654, discriminator loss = 0.7722\n",
      "4400/20000, perceptual loss = 0.1654, discriminator loss = 0.7722\n",
      "4450/20000, perceptual loss = 0.1766, discriminator loss = 0.5507\n",
      "4450/20000, perceptual loss = 0.1766, discriminator loss = 0.5507\n",
      "4500/20000, perceptual loss = 0.1835, discriminator loss = 0.4358\n",
      "4500/20000, perceptual loss = 0.1835, discriminator loss = 0.4358\n",
      "4550/20000, perceptual loss = 0.1752, discriminator loss = 0.5473\n",
      "4550/20000, perceptual loss = 0.1752, discriminator loss = 0.5473\n",
      "4600/20000, perceptual loss = 0.1755, discriminator loss = 0.6628\n",
      "4600/20000, perceptual loss = 0.1755, discriminator loss = 0.6628\n",
      "4650/20000, perceptual loss = 0.1723, discriminator loss = 0.6817\n",
      "4650/20000, perceptual loss = 0.1723, discriminator loss = 0.6817\n",
      "4700/20000, perceptual loss = 0.1744, discriminator loss = 0.4716\n",
      "4700/20000, perceptual loss = 0.1744, discriminator loss = 0.4716\n",
      "4750/20000, perceptual loss = 0.1745, discriminator loss = 0.4443\n",
      "4750/20000, perceptual loss = 0.1745, discriminator loss = 0.4443\n",
      "4800/20000, perceptual loss = 0.1765, discriminator loss = 0.3944\n",
      "4800/20000, perceptual loss = 0.1765, discriminator loss = 0.3944\n",
      "4850/20000, perceptual loss = 0.1627, discriminator loss = 0.4292\n",
      "4850/20000, perceptual loss = 0.1627, discriminator loss = 0.4292\n",
      "4900/20000, perceptual loss = 0.1810, discriminator loss = 0.6068\n",
      "4900/20000, perceptual loss = 0.1810, discriminator loss = 0.6068\n",
      "4950/20000, perceptual loss = 0.1602, discriminator loss = 0.3042\n",
      "4950/20000, perceptual loss = 0.1602, discriminator loss = 0.3042\n",
      "5000/20000, perceptual loss = 0.1758, discriminator loss = 0.9907\n",
      "5000/20000, perceptual loss = 0.1758, discriminator loss = 0.9907\n",
      "5050/20000, perceptual loss = 0.1759, discriminator loss = 0.6585\n",
      "5050/20000, perceptual loss = 0.1759, discriminator loss = 0.6585\n",
      "5100/20000, perceptual loss = 0.1728, discriminator loss = 0.4377\n",
      "5100/20000, perceptual loss = 0.1728, discriminator loss = 0.4377\n",
      "5150/20000, perceptual loss = 0.1680, discriminator loss = 0.3373\n",
      "5150/20000, perceptual loss = 0.1680, discriminator loss = 0.3373\n",
      "5200/20000, perceptual loss = 0.1713, discriminator loss = 0.3470\n",
      "5200/20000, perceptual loss = 0.1713, discriminator loss = 0.3470\n",
      "5250/20000, perceptual loss = 0.1814, discriminator loss = 0.7816\n",
      "5250/20000, perceptual loss = 0.1814, discriminator loss = 0.7816\n",
      "5300/20000, perceptual loss = 0.1713, discriminator loss = 0.6196\n",
      "5300/20000, perceptual loss = 0.1713, discriminator loss = 0.6196\n",
      "5350/20000, perceptual loss = 0.1818, discriminator loss = 0.4085\n",
      "5350/20000, perceptual loss = 0.1818, discriminator loss = 0.4085\n",
      "5400/20000, perceptual loss = 0.1681, discriminator loss = 0.6138\n",
      "5400/20000, perceptual loss = 0.1681, discriminator loss = 0.6138\n",
      "5450/20000, perceptual loss = 0.1738, discriminator loss = 0.5233\n",
      "5450/20000, perceptual loss = 0.1738, discriminator loss = 0.5233\n",
      "5500/20000, perceptual loss = 0.1744, discriminator loss = 0.4976\n",
      "5500/20000, perceptual loss = 0.1744, discriminator loss = 0.4976\n",
      "5550/20000, perceptual loss = 0.1699, discriminator loss = 0.6017\n",
      "5550/20000, perceptual loss = 0.1699, discriminator loss = 0.6017\n",
      "5600/20000, perceptual loss = 0.1749, discriminator loss = 0.3608\n",
      "5600/20000, perceptual loss = 0.1749, discriminator loss = 0.3608\n",
      "5650/20000, perceptual loss = 0.1798, discriminator loss = 0.5881\n",
      "5650/20000, perceptual loss = 0.1798, discriminator loss = 0.5881\n",
      "5700/20000, perceptual loss = 0.1754, discriminator loss = 0.5210\n",
      "5700/20000, perceptual loss = 0.1754, discriminator loss = 0.5210\n",
      "5750/20000, perceptual loss = 0.1752, discriminator loss = 0.4641\n",
      "5750/20000, perceptual loss = 0.1752, discriminator loss = 0.4641\n",
      "5800/20000, perceptual loss = 0.1735, discriminator loss = 0.4689\n",
      "5800/20000, perceptual loss = 0.1735, discriminator loss = 0.4689\n",
      "5850/20000, perceptual loss = 0.1749, discriminator loss = 0.4244\n",
      "5850/20000, perceptual loss = 0.1749, discriminator loss = 0.4244\n",
      "5900/20000, perceptual loss = 0.1625, discriminator loss = 0.4971\n",
      "5900/20000, perceptual loss = 0.1625, discriminator loss = 0.4971\n",
      "5950/20000, perceptual loss = 0.1727, discriminator loss = 0.3816\n",
      "5950/20000, perceptual loss = 0.1727, discriminator loss = 0.3816\n",
      "6000/20000, perceptual loss = 0.1747, discriminator loss = 0.4764\n",
      "6000/20000, perceptual loss = 0.1747, discriminator loss = 0.4764\n",
      "6050/20000, perceptual loss = 0.1713, discriminator loss = 0.3272\n",
      "6050/20000, perceptual loss = 0.1713, discriminator loss = 0.3272\n",
      "6100/20000, perceptual loss = 0.1817, discriminator loss = 0.4944\n",
      "6100/20000, perceptual loss = 0.1817, discriminator loss = 0.4944\n",
      "6150/20000, perceptual loss = 0.1773, discriminator loss = 0.3652\n",
      "6150/20000, perceptual loss = 0.1773, discriminator loss = 0.3652\n",
      "6200/20000, perceptual loss = 0.1704, discriminator loss = 0.4512\n",
      "6200/20000, perceptual loss = 0.1704, discriminator loss = 0.4512\n",
      "6250/20000, perceptual loss = 0.1698, discriminator loss = 0.5003\n",
      "6250/20000, perceptual loss = 0.1698, discriminator loss = 0.5003\n",
      "6300/20000, perceptual loss = 0.1659, discriminator loss = 0.3524\n",
      "6300/20000, perceptual loss = 0.1659, discriminator loss = 0.3524\n",
      "6350/20000, perceptual loss = 0.1687, discriminator loss = 0.4034\n",
      "6350/20000, perceptual loss = 0.1687, discriminator loss = 0.4034\n",
      "6400/20000, perceptual loss = 0.1692, discriminator loss = 0.4934\n",
      "6400/20000, perceptual loss = 0.1692, discriminator loss = 0.4934\n",
      "6450/20000, perceptual loss = 0.1717, discriminator loss = 0.4632\n",
      "6450/20000, perceptual loss = 0.1717, discriminator loss = 0.4632\n",
      "6500/20000, perceptual loss = 0.1710, discriminator loss = 0.3602\n",
      "6500/20000, perceptual loss = 0.1710, discriminator loss = 0.3602\n",
      "6550/20000, perceptual loss = 0.1742, discriminator loss = 0.3824\n",
      "6550/20000, perceptual loss = 0.1742, discriminator loss = 0.3824\n",
      "6600/20000, perceptual loss = 0.1667, discriminator loss = 0.3467\n",
      "6600/20000, perceptual loss = 0.1667, discriminator loss = 0.3467\n",
      "6650/20000, perceptual loss = 0.1758, discriminator loss = 0.3417\n",
      "6650/20000, perceptual loss = 0.1758, discriminator loss = 0.3417\n",
      "6700/20000, perceptual loss = 0.1735, discriminator loss = 0.3186\n",
      "6700/20000, perceptual loss = 0.1735, discriminator loss = 0.3186\n",
      "6750/20000, perceptual loss = 0.1791, discriminator loss = 0.3391\n",
      "6750/20000, perceptual loss = 0.1791, discriminator loss = 0.3391\n",
      "6800/20000, perceptual loss = 0.1725, discriminator loss = 0.3598\n",
      "6800/20000, perceptual loss = 0.1725, discriminator loss = 0.3598\n",
      "6850/20000, perceptual loss = 0.1688, discriminator loss = 0.3177\n",
      "6850/20000, perceptual loss = 0.1688, discriminator loss = 0.3177\n",
      "6900/20000, perceptual loss = 0.1625, discriminator loss = 0.3715\n",
      "6900/20000, perceptual loss = 0.1625, discriminator loss = 0.3715\n",
      "6950/20000, perceptual loss = 0.1705, discriminator loss = 0.3720\n",
      "6950/20000, perceptual loss = 0.1705, discriminator loss = 0.3720\n",
      "7000/20000, perceptual loss = 0.1695, discriminator loss = 0.4506\n",
      "7000/20000, perceptual loss = 0.1695, discriminator loss = 0.4506\n",
      "7050/20000, perceptual loss = 0.1647, discriminator loss = 0.4068\n",
      "7050/20000, perceptual loss = 0.1647, discriminator loss = 0.4068\n",
      "7100/20000, perceptual loss = 0.1568, discriminator loss = 0.3921\n",
      "7100/20000, perceptual loss = 0.1568, discriminator loss = 0.3921\n",
      "7150/20000, perceptual loss = 0.1604, discriminator loss = 0.3832\n",
      "7150/20000, perceptual loss = 0.1604, discriminator loss = 0.3832\n",
      "7200/20000, perceptual loss = 0.1550, discriminator loss = 0.3778\n",
      "7200/20000, perceptual loss = 0.1550, discriminator loss = 0.3778\n",
      "7250/20000, perceptual loss = 0.1507, discriminator loss = 0.3465\n",
      "7250/20000, perceptual loss = 0.1507, discriminator loss = 0.3465\n",
      "7300/20000, perceptual loss = 0.1507, discriminator loss = 0.4523\n",
      "7300/20000, perceptual loss = 0.1507, discriminator loss = 0.4523\n",
      "7350/20000, perceptual loss = 0.1543, discriminator loss = 0.4546\n",
      "7350/20000, perceptual loss = 0.1543, discriminator loss = 0.4546\n",
      "7400/20000, perceptual loss = 0.1528, discriminator loss = 0.4443\n",
      "7400/20000, perceptual loss = 0.1528, discriminator loss = 0.4443\n",
      "7450/20000, perceptual loss = 0.1454, discriminator loss = 0.3930\n",
      "7450/20000, perceptual loss = 0.1454, discriminator loss = 0.3930\n",
      "7500/20000, perceptual loss = 0.1518, discriminator loss = 0.4711\n",
      "7500/20000, perceptual loss = 0.1518, discriminator loss = 0.4711\n",
      "7550/20000, perceptual loss = 0.1538, discriminator loss = 0.4186\n",
      "7550/20000, perceptual loss = 0.1538, discriminator loss = 0.4186\n",
      "7600/20000, perceptual loss = 0.1496, discriminator loss = 0.5079\n",
      "7600/20000, perceptual loss = 0.1496, discriminator loss = 0.5079\n",
      "7650/20000, perceptual loss = 0.1407, discriminator loss = 0.4603\n",
      "7650/20000, perceptual loss = 0.1407, discriminator loss = 0.4603\n",
      "7700/20000, perceptual loss = 0.1355, discriminator loss = 0.5183\n",
      "7700/20000, perceptual loss = 0.1355, discriminator loss = 0.5183\n",
      "7750/20000, perceptual loss = 0.1388, discriminator loss = 0.4090\n",
      "7750/20000, perceptual loss = 0.1388, discriminator loss = 0.4090\n",
      "7800/20000, perceptual loss = 0.1353, discriminator loss = 0.5379\n",
      "7800/20000, perceptual loss = 0.1353, discriminator loss = 0.5379\n",
      "7850/20000, perceptual loss = 0.1398, discriminator loss = 0.5060\n",
      "7850/20000, perceptual loss = 0.1398, discriminator loss = 0.5060\n",
      "7900/20000, perceptual loss = 0.1294, discriminator loss = 0.4332\n",
      "7900/20000, perceptual loss = 0.1294, discriminator loss = 0.4332\n",
      "7950/20000, perceptual loss = 0.1346, discriminator loss = 0.4790\n",
      "7950/20000, perceptual loss = 0.1346, discriminator loss = 0.4790\n",
      "8000/20000, perceptual loss = 0.1302, discriminator loss = 0.4367\n",
      "8000/20000, perceptual loss = 0.1302, discriminator loss = 0.4367\n",
      "8050/20000, perceptual loss = 0.1247, discriminator loss = 0.5389\n",
      "8050/20000, perceptual loss = 0.1247, discriminator loss = 0.5389\n",
      "8100/20000, perceptual loss = 0.1421, discriminator loss = 0.4793\n",
      "8100/20000, perceptual loss = 0.1421, discriminator loss = 0.4793\n",
      "8150/20000, perceptual loss = 0.1241, discriminator loss = 0.5325\n",
      "8150/20000, perceptual loss = 0.1241, discriminator loss = 0.5325\n",
      "8200/20000, perceptual loss = 0.1277, discriminator loss = 0.4289\n",
      "8200/20000, perceptual loss = 0.1277, discriminator loss = 0.4289\n",
      "8250/20000, perceptual loss = 0.1274, discriminator loss = 0.4495\n",
      "8250/20000, perceptual loss = 0.1274, discriminator loss = 0.4495\n",
      "8300/20000, perceptual loss = 0.1296, discriminator loss = 0.4877\n",
      "8300/20000, perceptual loss = 0.1296, discriminator loss = 0.4877\n",
      "8350/20000, perceptual loss = 0.1317, discriminator loss = 0.4439\n",
      "8350/20000, perceptual loss = 0.1317, discriminator loss = 0.4439\n",
      "8400/20000, perceptual loss = 0.1182, discriminator loss = 0.4393\n",
      "8400/20000, perceptual loss = 0.1182, discriminator loss = 0.4393\n",
      "8450/20000, perceptual loss = 0.1252, discriminator loss = 0.4014\n",
      "8450/20000, perceptual loss = 0.1252, discriminator loss = 0.4014\n",
      "8500/20000, perceptual loss = 0.1267, discriminator loss = 0.3878\n",
      "8500/20000, perceptual loss = 0.1267, discriminator loss = 0.3878\n",
      "8550/20000, perceptual loss = 0.1239, discriminator loss = 0.3797\n",
      "8550/20000, perceptual loss = 0.1239, discriminator loss = 0.3797\n",
      "8600/20000, perceptual loss = 0.1211, discriminator loss = 0.4316\n",
      "8600/20000, perceptual loss = 0.1211, discriminator loss = 0.4316\n",
      "8650/20000, perceptual loss = 0.1176, discriminator loss = 0.4382\n",
      "8650/20000, perceptual loss = 0.1176, discriminator loss = 0.4382\n",
      "8700/20000, perceptual loss = 0.1249, discriminator loss = 0.4546\n",
      "8700/20000, perceptual loss = 0.1249, discriminator loss = 0.4546\n",
      "8750/20000, perceptual loss = 0.1239, discriminator loss = 0.4095\n",
      "8750/20000, perceptual loss = 0.1239, discriminator loss = 0.4095\n",
      "8800/20000, perceptual loss = 0.1161, discriminator loss = 0.3631\n",
      "8800/20000, perceptual loss = 0.1161, discriminator loss = 0.3631\n",
      "8850/20000, perceptual loss = 0.1174, discriminator loss = 0.3204\n",
      "8850/20000, perceptual loss = 0.1174, discriminator loss = 0.3204\n",
      "8900/20000, perceptual loss = 0.1239, discriminator loss = 0.3708\n",
      "8900/20000, perceptual loss = 0.1239, discriminator loss = 0.3708\n",
      "8950/20000, perceptual loss = 0.1138, discriminator loss = 0.3499\n",
      "8950/20000, perceptual loss = 0.1138, discriminator loss = 0.3499\n",
      "9000/20000, perceptual loss = 0.1204, discriminator loss = 0.3339\n",
      "9000/20000, perceptual loss = 0.1204, discriminator loss = 0.3339\n",
      "9050/20000, perceptual loss = 0.1200, discriminator loss = 0.3778\n",
      "9050/20000, perceptual loss = 0.1200, discriminator loss = 0.3778\n",
      "9100/20000, perceptual loss = 0.1102, discriminator loss = 0.3440\n",
      "9100/20000, perceptual loss = 0.1102, discriminator loss = 0.3440\n",
      "9150/20000, perceptual loss = 0.1174, discriminator loss = 0.4966\n",
      "9150/20000, perceptual loss = 0.1174, discriminator loss = 0.4966\n",
      "9200/20000, perceptual loss = 0.1196, discriminator loss = 0.3662\n",
      "9200/20000, perceptual loss = 0.1196, discriminator loss = 0.3662\n",
      "9250/20000, perceptual loss = 0.1104, discriminator loss = 0.4703\n",
      "9250/20000, perceptual loss = 0.1104, discriminator loss = 0.4703\n",
      "9300/20000, perceptual loss = 0.1191, discriminator loss = 0.4630\n",
      "9300/20000, perceptual loss = 0.1191, discriminator loss = 0.4630\n",
      "9350/20000, perceptual loss = 0.1163, discriminator loss = 0.3532\n",
      "9350/20000, perceptual loss = 0.1163, discriminator loss = 0.3532\n",
      "9400/20000, perceptual loss = 0.1149, discriminator loss = 0.3666\n",
      "9400/20000, perceptual loss = 0.1149, discriminator loss = 0.3666\n",
      "9450/20000, perceptual loss = 0.1120, discriminator loss = 0.4801\n",
      "9450/20000, perceptual loss = 0.1120, discriminator loss = 0.4801\n",
      "9500/20000, perceptual loss = 0.1183, discriminator loss = 0.3270\n",
      "9500/20000, perceptual loss = 0.1183, discriminator loss = 0.3270\n",
      "9550/20000, perceptual loss = 0.1120, discriminator loss = 0.3239\n",
      "9550/20000, perceptual loss = 0.1120, discriminator loss = 0.3239\n",
      "9600/20000, perceptual loss = 0.1139, discriminator loss = 0.4257\n",
      "9600/20000, perceptual loss = 0.1139, discriminator loss = 0.4257\n",
      "9650/20000, perceptual loss = 0.1145, discriminator loss = 0.4277\n",
      "9650/20000, perceptual loss = 0.1145, discriminator loss = 0.4277\n",
      "9700/20000, perceptual loss = 0.1170, discriminator loss = 0.4209\n",
      "9700/20000, perceptual loss = 0.1170, discriminator loss = 0.4209\n",
      "9750/20000, perceptual loss = 0.1170, discriminator loss = 0.3791\n",
      "9750/20000, perceptual loss = 0.1170, discriminator loss = 0.3791\n",
      "9800/20000, perceptual loss = 0.1111, discriminator loss = 0.3056\n",
      "9800/20000, perceptual loss = 0.1111, discriminator loss = 0.3056\n",
      "9850/20000, perceptual loss = 0.1080, discriminator loss = 0.3899\n",
      "9850/20000, perceptual loss = 0.1080, discriminator loss = 0.3899\n",
      "9900/20000, perceptual loss = 0.1204, discriminator loss = 0.3818\n",
      "9900/20000, perceptual loss = 0.1204, discriminator loss = 0.3818\n",
      "9950/20000, perceptual loss = 0.1145, discriminator loss = 0.3296\n",
      "9950/20000, perceptual loss = 0.1145, discriminator loss = 0.3296\n",
      "10000/20000, perceptual loss = 0.1096, discriminator loss = 0.4751\n",
      "10000/20000, perceptual loss = 0.1096, discriminator loss = 0.4751\n",
      "10050/20000, perceptual loss = 0.1135, discriminator loss = 0.3862\n",
      "10050/20000, perceptual loss = 0.1135, discriminator loss = 0.3862\n",
      "10100/20000, perceptual loss = 0.1138, discriminator loss = 0.3931\n",
      "10100/20000, perceptual loss = 0.1138, discriminator loss = 0.3931\n",
      "10150/20000, perceptual loss = 0.1049, discriminator loss = 0.4285\n",
      "10150/20000, perceptual loss = 0.1049, discriminator loss = 0.4285\n",
      "10200/20000, perceptual loss = 0.1159, discriminator loss = 0.2997\n",
      "10200/20000, perceptual loss = 0.1159, discriminator loss = 0.2997\n",
      "10250/20000, perceptual loss = 0.1068, discriminator loss = 0.4488\n",
      "10250/20000, perceptual loss = 0.1068, discriminator loss = 0.4488\n",
      "10300/20000, perceptual loss = 0.1179, discriminator loss = 0.3284\n",
      "10300/20000, perceptual loss = 0.1179, discriminator loss = 0.3284\n",
      "10350/20000, perceptual loss = 0.1179, discriminator loss = 0.4936\n",
      "10350/20000, perceptual loss = 0.1179, discriminator loss = 0.4936\n",
      "10400/20000, perceptual loss = 0.1156, discriminator loss = 0.3396\n",
      "10400/20000, perceptual loss = 0.1156, discriminator loss = 0.3396\n",
      "10450/20000, perceptual loss = 0.1115, discriminator loss = 0.2827\n",
      "10450/20000, perceptual loss = 0.1115, discriminator loss = 0.2827\n",
      "10500/20000, perceptual loss = 0.1102, discriminator loss = 0.4310\n",
      "10500/20000, perceptual loss = 0.1102, discriminator loss = 0.4310\n",
      "10550/20000, perceptual loss = 0.1045, discriminator loss = 0.3545\n",
      "10550/20000, perceptual loss = 0.1045, discriminator loss = 0.3545\n",
      "10600/20000, perceptual loss = 0.1109, discriminator loss = 0.3022\n",
      "10600/20000, perceptual loss = 0.1109, discriminator loss = 0.3022\n",
      "10650/20000, perceptual loss = 0.1117, discriminator loss = 0.3919\n",
      "10650/20000, perceptual loss = 0.1117, discriminator loss = 0.3919\n",
      "10700/20000, perceptual loss = 0.1027, discriminator loss = 0.4614\n",
      "10700/20000, perceptual loss = 0.1027, discriminator loss = 0.4614\n",
      "10750/20000, perceptual loss = 0.1102, discriminator loss = 0.3685\n",
      "10750/20000, perceptual loss = 0.1102, discriminator loss = 0.3685\n",
      "10800/20000, perceptual loss = 0.1100, discriminator loss = 0.2802\n",
      "10800/20000, perceptual loss = 0.1100, discriminator loss = 0.2802\n",
      "10850/20000, perceptual loss = 0.1174, discriminator loss = 0.3518\n",
      "10850/20000, perceptual loss = 0.1174, discriminator loss = 0.3518\n",
      "10900/20000, perceptual loss = 0.1106, discriminator loss = 0.3789\n",
      "10900/20000, perceptual loss = 0.1106, discriminator loss = 0.3789\n",
      "10950/20000, perceptual loss = 0.1049, discriminator loss = 0.3242\n",
      "10950/20000, perceptual loss = 0.1049, discriminator loss = 0.3242\n",
      "11000/20000, perceptual loss = 0.1024, discriminator loss = 0.3587\n",
      "11000/20000, perceptual loss = 0.1024, discriminator loss = 0.3587\n",
      "11050/20000, perceptual loss = 0.1108, discriminator loss = 0.3956\n",
      "11050/20000, perceptual loss = 0.1108, discriminator loss = 0.3956\n",
      "11100/20000, perceptual loss = 0.1136, discriminator loss = 0.3214\n",
      "11100/20000, perceptual loss = 0.1136, discriminator loss = 0.3214\n",
      "11150/20000, perceptual loss = 0.1160, discriminator loss = 0.2683\n",
      "11150/20000, perceptual loss = 0.1160, discriminator loss = 0.2683\n",
      "11200/20000, perceptual loss = 0.1074, discriminator loss = 0.3854\n",
      "11200/20000, perceptual loss = 0.1074, discriminator loss = 0.3854\n",
      "11250/20000, perceptual loss = 0.1122, discriminator loss = 0.3228\n",
      "11250/20000, perceptual loss = 0.1122, discriminator loss = 0.3228\n",
      "11300/20000, perceptual loss = 0.1090, discriminator loss = 0.4117\n",
      "11300/20000, perceptual loss = 0.1090, discriminator loss = 0.4117\n",
      "11350/20000, perceptual loss = 0.1086, discriminator loss = 0.3924\n",
      "11350/20000, perceptual loss = 0.1086, discriminator loss = 0.3924\n",
      "11400/20000, perceptual loss = 0.1050, discriminator loss = 0.4017\n",
      "11400/20000, perceptual loss = 0.1050, discriminator loss = 0.4017\n",
      "11450/20000, perceptual loss = 0.1099, discriminator loss = 0.2989\n",
      "11450/20000, perceptual loss = 0.1099, discriminator loss = 0.2989\n",
      "11500/20000, perceptual loss = 0.1074, discriminator loss = 0.4030\n",
      "11500/20000, perceptual loss = 0.1074, discriminator loss = 0.4030\n",
      "11550/20000, perceptual loss = 0.1108, discriminator loss = 0.3435\n",
      "11550/20000, perceptual loss = 0.1108, discriminator loss = 0.3435\n",
      "11600/20000, perceptual loss = 0.1092, discriminator loss = 0.4027\n",
      "11600/20000, perceptual loss = 0.1092, discriminator loss = 0.4027\n",
      "11650/20000, perceptual loss = 0.1017, discriminator loss = 0.3671\n",
      "11650/20000, perceptual loss = 0.1017, discriminator loss = 0.3671\n",
      "11700/20000, perceptual loss = 0.1065, discriminator loss = 0.3793\n",
      "11700/20000, perceptual loss = 0.1065, discriminator loss = 0.3793\n",
      "11750/20000, perceptual loss = 0.1060, discriminator loss = 0.4013\n",
      "11750/20000, perceptual loss = 0.1060, discriminator loss = 0.4013\n",
      "11800/20000, perceptual loss = 0.1129, discriminator loss = 0.2560\n",
      "11800/20000, perceptual loss = 0.1129, discriminator loss = 0.2560\n",
      "11850/20000, perceptual loss = 0.1045, discriminator loss = 0.2866\n",
      "11850/20000, perceptual loss = 0.1045, discriminator loss = 0.2866\n",
      "11900/20000, perceptual loss = 0.1039, discriminator loss = 0.2952\n",
      "11900/20000, perceptual loss = 0.1039, discriminator loss = 0.2952\n",
      "11950/20000, perceptual loss = 0.1053, discriminator loss = 0.4143\n",
      "11950/20000, perceptual loss = 0.1053, discriminator loss = 0.4143\n",
      "12000/20000, perceptual loss = 0.1047, discriminator loss = 0.2425\n",
      "12000/20000, perceptual loss = 0.1047, discriminator loss = 0.2425\n",
      "12050/20000, perceptual loss = 0.1082, discriminator loss = 0.4789\n",
      "12050/20000, perceptual loss = 0.1082, discriminator loss = 0.4789\n",
      "12100/20000, perceptual loss = 0.1124, discriminator loss = 0.3475\n",
      "12100/20000, perceptual loss = 0.1124, discriminator loss = 0.3475\n",
      "12150/20000, perceptual loss = 0.1090, discriminator loss = 0.2942\n",
      "12150/20000, perceptual loss = 0.1090, discriminator loss = 0.2942\n",
      "12200/20000, perceptual loss = 0.1066, discriminator loss = 0.4384\n",
      "12200/20000, perceptual loss = 0.1066, discriminator loss = 0.4384\n",
      "12250/20000, perceptual loss = 0.1102, discriminator loss = 0.3118\n",
      "12250/20000, perceptual loss = 0.1102, discriminator loss = 0.3118\n",
      "12300/20000, perceptual loss = 0.1144, discriminator loss = 0.4371\n",
      "12300/20000, perceptual loss = 0.1144, discriminator loss = 0.4371\n",
      "12350/20000, perceptual loss = 0.1070, discriminator loss = 0.3044\n",
      "12350/20000, perceptual loss = 0.1070, discriminator loss = 0.3044\n",
      "12400/20000, perceptual loss = 0.1116, discriminator loss = 0.3921\n",
      "12400/20000, perceptual loss = 0.1116, discriminator loss = 0.3921\n",
      "12450/20000, perceptual loss = 0.0973, discriminator loss = 0.2385\n",
      "12450/20000, perceptual loss = 0.0973, discriminator loss = 0.2385\n",
      "12500/20000, perceptual loss = 0.1099, discriminator loss = 0.3604\n",
      "12500/20000, perceptual loss = 0.1099, discriminator loss = 0.3604\n",
      "12550/20000, perceptual loss = 0.1066, discriminator loss = 0.2811\n",
      "12550/20000, perceptual loss = 0.1066, discriminator loss = 0.2811\n",
      "12600/20000, perceptual loss = 0.1027, discriminator loss = 0.3332\n",
      "12600/20000, perceptual loss = 0.1027, discriminator loss = 0.3332\n",
      "12650/20000, perceptual loss = 0.1028, discriminator loss = 0.2626\n",
      "12650/20000, perceptual loss = 0.1028, discriminator loss = 0.2626\n",
      "12700/20000, perceptual loss = 0.1044, discriminator loss = 0.3582\n",
      "12700/20000, perceptual loss = 0.1044, discriminator loss = 0.3582\n",
      "12750/20000, perceptual loss = 0.0971, discriminator loss = 0.3627\n",
      "12750/20000, perceptual loss = 0.0971, discriminator loss = 0.3627\n",
      "12800/20000, perceptual loss = 0.0938, discriminator loss = 0.2833\n",
      "12800/20000, perceptual loss = 0.0938, discriminator loss = 0.2833\n",
      "12850/20000, perceptual loss = 0.1072, discriminator loss = 0.3285\n",
      "12850/20000, perceptual loss = 0.1072, discriminator loss = 0.3285\n",
      "12900/20000, perceptual loss = 0.1096, discriminator loss = 0.3129\n",
      "12900/20000, perceptual loss = 0.1096, discriminator loss = 0.3129\n",
      "12950/20000, perceptual loss = 0.1086, discriminator loss = 0.3467\n",
      "12950/20000, perceptual loss = 0.1086, discriminator loss = 0.3467\n",
      "13000/20000, perceptual loss = 0.1039, discriminator loss = 0.2791\n",
      "13000/20000, perceptual loss = 0.1039, discriminator loss = 0.2791\n",
      "13050/20000, perceptual loss = 0.1044, discriminator loss = 0.3301\n",
      "13050/20000, perceptual loss = 0.1044, discriminator loss = 0.3301\n",
      "13100/20000, perceptual loss = 0.1008, discriminator loss = 0.3163\n",
      "13100/20000, perceptual loss = 0.1008, discriminator loss = 0.3163\n",
      "13150/20000, perceptual loss = 0.1086, discriminator loss = 0.2466\n",
      "13150/20000, perceptual loss = 0.1086, discriminator loss = 0.2466\n",
      "13200/20000, perceptual loss = 0.1018, discriminator loss = 0.3401\n",
      "13200/20000, perceptual loss = 0.1018, discriminator loss = 0.3401\n",
      "13250/20000, perceptual loss = 0.1082, discriminator loss = 0.2799\n",
      "13250/20000, perceptual loss = 0.1082, discriminator loss = 0.2799\n",
      "13300/20000, perceptual loss = 0.1087, discriminator loss = 0.2975\n",
      "13300/20000, perceptual loss = 0.1087, discriminator loss = 0.2975\n",
      "13350/20000, perceptual loss = 0.1169, discriminator loss = 0.2698\n",
      "13350/20000, perceptual loss = 0.1169, discriminator loss = 0.2698\n",
      "13400/20000, perceptual loss = 0.0956, discriminator loss = 0.3230\n",
      "13400/20000, perceptual loss = 0.0956, discriminator loss = 0.3230\n",
      "13450/20000, perceptual loss = 0.1080, discriminator loss = 0.2625\n",
      "13450/20000, perceptual loss = 0.1080, discriminator loss = 0.2625\n",
      "13500/20000, perceptual loss = 0.1056, discriminator loss = 0.2810\n",
      "13500/20000, perceptual loss = 0.1056, discriminator loss = 0.2810\n",
      "13550/20000, perceptual loss = 0.1096, discriminator loss = 0.3057\n",
      "13550/20000, perceptual loss = 0.1096, discriminator loss = 0.3057\n",
      "13600/20000, perceptual loss = 0.1045, discriminator loss = 0.3034\n",
      "13600/20000, perceptual loss = 0.1045, discriminator loss = 0.3034\n",
      "13650/20000, perceptual loss = 0.1057, discriminator loss = 0.2300\n",
      "13650/20000, perceptual loss = 0.1057, discriminator loss = 0.2300\n",
      "13700/20000, perceptual loss = 0.0990, discriminator loss = 0.2768\n",
      "13700/20000, perceptual loss = 0.0990, discriminator loss = 0.2768\n",
      "13750/20000, perceptual loss = 0.1103, discriminator loss = 0.2909\n",
      "13750/20000, perceptual loss = 0.1103, discriminator loss = 0.2909\n",
      "13800/20000, perceptual loss = 0.0977, discriminator loss = 0.3154\n",
      "13800/20000, perceptual loss = 0.0977, discriminator loss = 0.3154\n",
      "13850/20000, perceptual loss = 0.1004, discriminator loss = 0.2994\n",
      "13850/20000, perceptual loss = 0.1004, discriminator loss = 0.2994\n",
      "13900/20000, perceptual loss = 0.1010, discriminator loss = 0.3077\n",
      "13900/20000, perceptual loss = 0.1010, discriminator loss = 0.3077\n",
      "13950/20000, perceptual loss = 0.1007, discriminator loss = 0.2987\n",
      "13950/20000, perceptual loss = 0.1007, discriminator loss = 0.2987\n",
      "14000/20000, perceptual loss = 0.1089, discriminator loss = 0.3135\n",
      "14000/20000, perceptual loss = 0.1089, discriminator loss = 0.3135\n",
      "14050/20000, perceptual loss = 0.1079, discriminator loss = 0.2667\n",
      "14050/20000, perceptual loss = 0.1079, discriminator loss = 0.2667\n",
      "14100/20000, perceptual loss = 0.1054, discriminator loss = 0.2663\n",
      "14100/20000, perceptual loss = 0.1054, discriminator loss = 0.2663\n",
      "14150/20000, perceptual loss = 0.1091, discriminator loss = 0.2335\n",
      "14150/20000, perceptual loss = 0.1091, discriminator loss = 0.2335\n",
      "14200/20000, perceptual loss = 0.1077, discriminator loss = 0.2734\n",
      "14200/20000, perceptual loss = 0.1077, discriminator loss = 0.2734\n",
      "14250/20000, perceptual loss = 0.1015, discriminator loss = 0.2150\n",
      "14250/20000, perceptual loss = 0.1015, discriminator loss = 0.2150\n",
      "14300/20000, perceptual loss = 0.1030, discriminator loss = 0.2508\n",
      "14300/20000, perceptual loss = 0.1030, discriminator loss = 0.2508\n",
      "14350/20000, perceptual loss = 0.1059, discriminator loss = 0.1599\n",
      "14350/20000, perceptual loss = 0.1059, discriminator loss = 0.1599\n",
      "14400/20000, perceptual loss = 0.1135, discriminator loss = 0.2774\n",
      "14400/20000, perceptual loss = 0.1135, discriminator loss = 0.2774\n",
      "14450/20000, perceptual loss = 0.1101, discriminator loss = 0.1950\n",
      "14450/20000, perceptual loss = 0.1101, discriminator loss = 0.1950\n",
      "14500/20000, perceptual loss = 0.0986, discriminator loss = 0.1296\n",
      "14500/20000, perceptual loss = 0.0986, discriminator loss = 0.1296\n",
      "14550/20000, perceptual loss = 0.1053, discriminator loss = 0.1564\n",
      "14550/20000, perceptual loss = 0.1053, discriminator loss = 0.1564\n",
      "14600/20000, perceptual loss = 0.1048, discriminator loss = 0.1752\n",
      "14600/20000, perceptual loss = 0.1048, discriminator loss = 0.1752\n",
      "14650/20000, perceptual loss = 0.1056, discriminator loss = 0.2238\n",
      "14650/20000, perceptual loss = 0.1056, discriminator loss = 0.2238\n",
      "14700/20000, perceptual loss = 0.1025, discriminator loss = 0.1804\n",
      "14700/20000, perceptual loss = 0.1025, discriminator loss = 0.1804\n",
      "14750/20000, perceptual loss = 0.1042, discriminator loss = 0.2280\n",
      "14750/20000, perceptual loss = 0.1042, discriminator loss = 0.2280\n",
      "14800/20000, perceptual loss = 0.1044, discriminator loss = 0.1974\n",
      "14800/20000, perceptual loss = 0.1044, discriminator loss = 0.1974\n",
      "14850/20000, perceptual loss = 0.1018, discriminator loss = 0.1715\n",
      "14850/20000, perceptual loss = 0.1018, discriminator loss = 0.1715\n",
      "14900/20000, perceptual loss = 0.1035, discriminator loss = 0.2377\n",
      "14900/20000, perceptual loss = 0.1035, discriminator loss = 0.2377\n",
      "14950/20000, perceptual loss = 0.1036, discriminator loss = 0.2055\n",
      "14950/20000, perceptual loss = 0.1036, discriminator loss = 0.2055\n",
      "15000/20000, perceptual loss = 0.1085, discriminator loss = 0.2569\n",
      "15000/20000, perceptual loss = 0.1085, discriminator loss = 0.2569\n",
      "15050/20000, perceptual loss = 0.1039, discriminator loss = 0.1929\n",
      "15050/20000, perceptual loss = 0.1039, discriminator loss = 0.1929\n",
      "15100/20000, perceptual loss = 0.1067, discriminator loss = 0.1527\n",
      "15100/20000, perceptual loss = 0.1067, discriminator loss = 0.1527\n",
      "15150/20000, perceptual loss = 0.1063, discriminator loss = 0.1692\n",
      "15150/20000, perceptual loss = 0.1063, discriminator loss = 0.1692\n",
      "15200/20000, perceptual loss = 0.0982, discriminator loss = 0.1990\n",
      "15200/20000, perceptual loss = 0.0982, discriminator loss = 0.1990\n",
      "15250/20000, perceptual loss = 0.0991, discriminator loss = 0.1688\n",
      "15250/20000, perceptual loss = 0.0991, discriminator loss = 0.1688\n",
      "15300/20000, perceptual loss = 0.1054, discriminator loss = 0.1503\n",
      "15300/20000, perceptual loss = 0.1054, discriminator loss = 0.1503\n",
      "15350/20000, perceptual loss = 0.1041, discriminator loss = 0.1548\n",
      "15350/20000, perceptual loss = 0.1041, discriminator loss = 0.1548\n",
      "15400/20000, perceptual loss = 0.1003, discriminator loss = 0.1689\n",
      "15400/20000, perceptual loss = 0.1003, discriminator loss = 0.1689\n",
      "15450/20000, perceptual loss = 0.1052, discriminator loss = 0.1520\n",
      "15450/20000, perceptual loss = 0.1052, discriminator loss = 0.1520\n",
      "15500/20000, perceptual loss = 0.1132, discriminator loss = 0.1981\n",
      "15500/20000, perceptual loss = 0.1132, discriminator loss = 0.1981\n",
      "15550/20000, perceptual loss = 0.1022, discriminator loss = 0.1475\n",
      "15550/20000, perceptual loss = 0.1022, discriminator loss = 0.1475\n",
      "15600/20000, perceptual loss = 0.1040, discriminator loss = 0.2272\n",
      "15600/20000, perceptual loss = 0.1040, discriminator loss = 0.2272\n",
      "15650/20000, perceptual loss = 0.1010, discriminator loss = 0.1228\n",
      "15650/20000, perceptual loss = 0.1010, discriminator loss = 0.1228\n",
      "15700/20000, perceptual loss = 0.1052, discriminator loss = 0.1742\n",
      "15700/20000, perceptual loss = 0.1052, discriminator loss = 0.1742\n",
      "15750/20000, perceptual loss = 0.1131, discriminator loss = 0.1923\n",
      "15750/20000, perceptual loss = 0.1131, discriminator loss = 0.1923\n",
      "15800/20000, perceptual loss = 0.1070, discriminator loss = 0.1614\n",
      "15800/20000, perceptual loss = 0.1070, discriminator loss = 0.1614\n",
      "15850/20000, perceptual loss = 0.0991, discriminator loss = 0.1718\n",
      "15850/20000, perceptual loss = 0.0991, discriminator loss = 0.1718\n",
      "15900/20000, perceptual loss = 0.1104, discriminator loss = 0.1183\n",
      "15900/20000, perceptual loss = 0.1104, discriminator loss = 0.1183\n",
      "15950/20000, perceptual loss = 0.1041, discriminator loss = 0.1868\n",
      "15950/20000, perceptual loss = 0.1041, discriminator loss = 0.1868\n",
      "16000/20000, perceptual loss = 0.1038, discriminator loss = 0.1594\n",
      "16000/20000, perceptual loss = 0.1038, discriminator loss = 0.1594\n",
      "16050/20000, perceptual loss = 0.1030, discriminator loss = 0.1355\n",
      "16050/20000, perceptual loss = 0.1030, discriminator loss = 0.1355\n",
      "16100/20000, perceptual loss = 0.1050, discriminator loss = 0.1892\n",
      "16100/20000, perceptual loss = 0.1050, discriminator loss = 0.1892\n",
      "16150/20000, perceptual loss = 0.1019, discriminator loss = 0.1436\n",
      "16150/20000, perceptual loss = 0.1019, discriminator loss = 0.1436\n",
      "16200/20000, perceptual loss = 0.1022, discriminator loss = 0.2107\n",
      "16200/20000, perceptual loss = 0.1022, discriminator loss = 0.2107\n",
      "16250/20000, perceptual loss = 0.1053, discriminator loss = 0.1521\n",
      "16250/20000, perceptual loss = 0.1053, discriminator loss = 0.1521\n",
      "16300/20000, perceptual loss = 0.1011, discriminator loss = 0.1273\n",
      "16300/20000, perceptual loss = 0.1011, discriminator loss = 0.1273\n",
      "16350/20000, perceptual loss = 0.1098, discriminator loss = 0.1888\n",
      "16350/20000, perceptual loss = 0.1098, discriminator loss = 0.1888\n",
      "16400/20000, perceptual loss = 0.1009, discriminator loss = 0.1749\n",
      "16400/20000, perceptual loss = 0.1009, discriminator loss = 0.1749\n",
      "16450/20000, perceptual loss = 0.1056, discriminator loss = 0.1331\n",
      "16450/20000, perceptual loss = 0.1056, discriminator loss = 0.1331\n",
      "16500/20000, perceptual loss = 0.1035, discriminator loss = 0.1476\n",
      "16500/20000, perceptual loss = 0.1035, discriminator loss = 0.1476\n",
      "16550/20000, perceptual loss = 0.1029, discriminator loss = 0.1292\n",
      "16550/20000, perceptual loss = 0.1029, discriminator loss = 0.1292\n",
      "16600/20000, perceptual loss = 0.0968, discriminator loss = 0.1644\n",
      "16600/20000, perceptual loss = 0.0968, discriminator loss = 0.1644\n",
      "16650/20000, perceptual loss = 0.1016, discriminator loss = 0.1670\n",
      "16650/20000, perceptual loss = 0.1016, discriminator loss = 0.1670\n",
      "16700/20000, perceptual loss = 0.1030, discriminator loss = 0.1924\n",
      "16700/20000, perceptual loss = 0.1030, discriminator loss = 0.1924\n",
      "16750/20000, perceptual loss = 0.1037, discriminator loss = 0.1471\n",
      "16750/20000, perceptual loss = 0.1037, discriminator loss = 0.1471\n",
      "16800/20000, perceptual loss = 0.1085, discriminator loss = 0.1641\n",
      "16800/20000, perceptual loss = 0.1085, discriminator loss = 0.1641\n",
      "16850/20000, perceptual loss = 0.1055, discriminator loss = 0.1387\n",
      "16850/20000, perceptual loss = 0.1055, discriminator loss = 0.1387\n",
      "16900/20000, perceptual loss = 0.1056, discriminator loss = 0.1869\n",
      "16900/20000, perceptual loss = 0.1056, discriminator loss = 0.1869\n",
      "16950/20000, perceptual loss = 0.1006, discriminator loss = 0.1288\n",
      "16950/20000, perceptual loss = 0.1006, discriminator loss = 0.1288\n",
      "17000/20000, perceptual loss = 0.1061, discriminator loss = 0.1681\n",
      "17000/20000, perceptual loss = 0.1061, discriminator loss = 0.1681\n",
      "17050/20000, perceptual loss = 0.1019, discriminator loss = 0.1615\n",
      "17050/20000, perceptual loss = 0.1019, discriminator loss = 0.1615\n",
      "17100/20000, perceptual loss = 0.1007, discriminator loss = 0.1889\n",
      "17100/20000, perceptual loss = 0.1007, discriminator loss = 0.1889\n",
      "17150/20000, perceptual loss = 0.0995, discriminator loss = 0.1272\n",
      "17150/20000, perceptual loss = 0.0995, discriminator loss = 0.1272\n",
      "17200/20000, perceptual loss = 0.0984, discriminator loss = 0.2251\n",
      "17200/20000, perceptual loss = 0.0984, discriminator loss = 0.2251\n",
      "17250/20000, perceptual loss = 0.0996, discriminator loss = 0.0947\n",
      "17250/20000, perceptual loss = 0.0996, discriminator loss = 0.0947\n",
      "17300/20000, perceptual loss = 0.1103, discriminator loss = 0.0796\n",
      "17300/20000, perceptual loss = 0.1103, discriminator loss = 0.0796\n",
      "17350/20000, perceptual loss = 0.1011, discriminator loss = 0.1723\n",
      "17350/20000, perceptual loss = 0.1011, discriminator loss = 0.1723\n",
      "17400/20000, perceptual loss = 0.1025, discriminator loss = 0.1335\n",
      "17400/20000, perceptual loss = 0.1025, discriminator loss = 0.1335\n",
      "17450/20000, perceptual loss = 0.1042, discriminator loss = 0.1032\n",
      "17450/20000, perceptual loss = 0.1042, discriminator loss = 0.1032\n",
      "17500/20000, perceptual loss = 0.0997, discriminator loss = 0.1455\n",
      "17500/20000, perceptual loss = 0.0997, discriminator loss = 0.1455\n",
      "17550/20000, perceptual loss = 0.1010, discriminator loss = 0.1699\n",
      "17550/20000, perceptual loss = 0.1010, discriminator loss = 0.1699\n",
      "17600/20000, perceptual loss = 0.1054, discriminator loss = 0.1014\n",
      "17600/20000, perceptual loss = 0.1054, discriminator loss = 0.1014\n",
      "17650/20000, perceptual loss = 0.0999, discriminator loss = 0.0983\n",
      "17650/20000, perceptual loss = 0.0999, discriminator loss = 0.0983\n",
      "17700/20000, perceptual loss = 0.1053, discriminator loss = 0.1418\n",
      "17700/20000, perceptual loss = 0.1053, discriminator loss = 0.1418\n",
      "17750/20000, perceptual loss = 0.0962, discriminator loss = 0.1100\n",
      "17750/20000, perceptual loss = 0.0962, discriminator loss = 0.1100\n",
      "17800/20000, perceptual loss = 0.0991, discriminator loss = 0.1571\n",
      "17800/20000, perceptual loss = 0.0991, discriminator loss = 0.1571\n",
      "17850/20000, perceptual loss = 0.0953, discriminator loss = 0.1241\n",
      "17850/20000, perceptual loss = 0.0953, discriminator loss = 0.1241\n",
      "17900/20000, perceptual loss = 0.1095, discriminator loss = 0.1254\n",
      "17900/20000, perceptual loss = 0.1095, discriminator loss = 0.1254\n",
      "17950/20000, perceptual loss = 0.1056, discriminator loss = 0.1862\n",
      "17950/20000, perceptual loss = 0.1056, discriminator loss = 0.1862\n",
      "18000/20000, perceptual loss = 0.1055, discriminator loss = 0.1309\n",
      "18000/20000, perceptual loss = 0.1055, discriminator loss = 0.1309\n",
      "18050/20000, perceptual loss = 0.0935, discriminator loss = 0.1527\n",
      "18050/20000, perceptual loss = 0.0935, discriminator loss = 0.1527\n",
      "18100/20000, perceptual loss = 0.1052, discriminator loss = 0.1434\n",
      "18100/20000, perceptual loss = 0.1052, discriminator loss = 0.1434\n",
      "18150/20000, perceptual loss = 0.0992, discriminator loss = 0.1484\n",
      "18150/20000, perceptual loss = 0.0992, discriminator loss = 0.1484\n",
      "18200/20000, perceptual loss = 0.1007, discriminator loss = 0.1425\n",
      "18200/20000, perceptual loss = 0.1007, discriminator loss = 0.1425\n",
      "18250/20000, perceptual loss = 0.0998, discriminator loss = 0.1734\n",
      "18250/20000, perceptual loss = 0.0998, discriminator loss = 0.1734\n",
      "18300/20000, perceptual loss = 0.1013, discriminator loss = 0.1652\n",
      "18300/20000, perceptual loss = 0.1013, discriminator loss = 0.1652\n",
      "18350/20000, perceptual loss = 0.1107, discriminator loss = 0.1856\n",
      "18350/20000, perceptual loss = 0.1107, discriminator loss = 0.1856\n",
      "18400/20000, perceptual loss = 0.0983, discriminator loss = 0.1536\n",
      "18400/20000, perceptual loss = 0.0983, discriminator loss = 0.1536\n",
      "18450/20000, perceptual loss = 0.1029, discriminator loss = 0.1591\n",
      "18450/20000, perceptual loss = 0.1029, discriminator loss = 0.1591\n",
      "18500/20000, perceptual loss = 0.1047, discriminator loss = 0.1453\n",
      "18500/20000, perceptual loss = 0.1047, discriminator loss = 0.1453\n",
      "18550/20000, perceptual loss = 0.1102, discriminator loss = 0.2048\n",
      "18550/20000, perceptual loss = 0.1102, discriminator loss = 0.2048\n",
      "18600/20000, perceptual loss = 0.1026, discriminator loss = 0.1708\n",
      "18600/20000, perceptual loss = 0.1026, discriminator loss = 0.1708\n",
      "18650/20000, perceptual loss = 0.1054, discriminator loss = 0.1595\n",
      "18650/20000, perceptual loss = 0.1054, discriminator loss = 0.1595\n",
      "18700/20000, perceptual loss = 0.1125, discriminator loss = 0.1678\n",
      "18700/20000, perceptual loss = 0.1125, discriminator loss = 0.1678\n",
      "18750/20000, perceptual loss = 0.0960, discriminator loss = 0.2065\n",
      "18750/20000, perceptual loss = 0.0960, discriminator loss = 0.2065\n",
      "18800/20000, perceptual loss = 0.1078, discriminator loss = 0.1587\n",
      "18800/20000, perceptual loss = 0.1078, discriminator loss = 0.1587\n",
      "18850/20000, perceptual loss = 0.0995, discriminator loss = 0.1113\n",
      "18850/20000, perceptual loss = 0.0995, discriminator loss = 0.1113\n",
      "18900/20000, perceptual loss = 0.1045, discriminator loss = 0.1992\n",
      "18900/20000, perceptual loss = 0.1045, discriminator loss = 0.1992\n",
      "18950/20000, perceptual loss = 0.1084, discriminator loss = 0.1527\n",
      "18950/20000, perceptual loss = 0.1084, discriminator loss = 0.1527\n",
      "19000/20000, perceptual loss = 0.1021, discriminator loss = 0.1812\n",
      "19000/20000, perceptual loss = 0.1021, discriminator loss = 0.1812\n",
      "19050/20000, perceptual loss = 0.1075, discriminator loss = 0.1305\n",
      "19050/20000, perceptual loss = 0.1075, discriminator loss = 0.1305\n",
      "19100/20000, perceptual loss = 0.0964, discriminator loss = 0.1806\n",
      "19100/20000, perceptual loss = 0.0964, discriminator loss = 0.1806\n",
      "19150/20000, perceptual loss = 0.0995, discriminator loss = 0.1691\n",
      "19150/20000, perceptual loss = 0.0995, discriminator loss = 0.1691\n",
      "19200/20000, perceptual loss = 0.1099, discriminator loss = 0.1729\n",
      "19200/20000, perceptual loss = 0.1099, discriminator loss = 0.1729\n",
      "19250/20000, perceptual loss = 0.1035, discriminator loss = 0.1652\n",
      "19250/20000, perceptual loss = 0.1035, discriminator loss = 0.1652\n",
      "19300/20000, perceptual loss = 0.1105, discriminator loss = 0.1808\n",
      "19300/20000, perceptual loss = 0.1105, discriminator loss = 0.1808\n",
      "19350/20000, perceptual loss = 0.1055, discriminator loss = 0.1762\n",
      "19350/20000, perceptual loss = 0.1055, discriminator loss = 0.1762\n",
      "19400/20000, perceptual loss = 0.0954, discriminator loss = 0.1838\n",
      "19400/20000, perceptual loss = 0.0954, discriminator loss = 0.1838\n",
      "19450/20000, perceptual loss = 0.1013, discriminator loss = 0.1785\n",
      "19450/20000, perceptual loss = 0.1013, discriminator loss = 0.1785\n",
      "19500/20000, perceptual loss = 0.1045, discriminator loss = 0.1977\n",
      "19500/20000, perceptual loss = 0.1045, discriminator loss = 0.1977\n",
      "19550/20000, perceptual loss = 0.1104, discriminator loss = 0.1647\n",
      "19550/20000, perceptual loss = 0.1104, discriminator loss = 0.1647\n",
      "19600/20000, perceptual loss = 0.0944, discriminator loss = 0.1624\n",
      "19600/20000, perceptual loss = 0.0944, discriminator loss = 0.1624\n",
      "19650/20000, perceptual loss = 0.1037, discriminator loss = 0.1648\n",
      "19650/20000, perceptual loss = 0.1037, discriminator loss = 0.1648\n",
      "19700/20000, perceptual loss = 0.1033, discriminator loss = 0.2080\n",
      "19700/20000, perceptual loss = 0.1033, discriminator loss = 0.2080\n",
      "19750/20000, perceptual loss = 0.1002, discriminator loss = 0.1430\n",
      "19750/20000, perceptual loss = 0.1002, discriminator loss = 0.1430\n",
      "19800/20000, perceptual loss = 0.1011, discriminator loss = 0.1549\n",
      "19800/20000, perceptual loss = 0.1011, discriminator loss = 0.1549\n",
      "19850/20000, perceptual loss = 0.1048, discriminator loss = 0.1692\n",
      "19850/20000, perceptual loss = 0.1048, discriminator loss = 0.1692\n",
      "19900/20000, perceptual loss = 0.1060, discriminator loss = 0.1703\n",
      "19900/20000, perceptual loss = 0.1060, discriminator loss = 0.1703\n",
      "19950/20000, perceptual loss = 0.0983, discriminator loss = 0.2237\n",
      "19950/20000, perceptual loss = 0.0983, discriminator loss = 0.2237\n",
      "20000/20000, perceptual loss = 0.1006, discriminator loss = 0.1855\n",
      "20000/20000, perceptual loss = 0.1006, discriminator loss = 0.1855\n"
     ]
    }
   ],
   "source": [
    "## Training pre-trained model and SRGAN based on pretrained model\n",
    "pre_trainer = SrganGeneratorTrainer(model=generator(), checkpoint_dir=f'.ckpt/pre_generator')\n",
    "history1 = pre_trainer.train(train_ds,\n",
    "                  valid_ds.take(10),\n",
    "                  steps=100000, \n",
    "                  evaluate_every=1000, \n",
    "                  save_best_only=False)\n",
    "\n",
    "pre_trainer.model.save_weights(weights_file('pre_generator.h5'))\n",
    "\n",
    "gan_generator = generator()\n",
    "gan_generator.load_weights(weights_file('pre_generator.h5'))\n",
    "\n",
    "gan_trainer = SrganTrainer(generator=gan_generator, discriminator=discriminator())\n",
    "history2 = gan_trainer.train(train_ds, steps=20000)\n",
    "\n",
    "gan_trainer.generator.save_weights(weights_file('gan_generator.h5'))\n",
    "gan_trainer.discriminator.save_weights(weights_file('gan_discriminator.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3EisFA-itc5q"
   },
   "outputs": [],
   "source": [
    "pre_generator = generator()\n",
    "gan_generator = generator()\n",
    "\n",
    "pre_generator.load_weights(weights_file('pre_generator.h5'))\n",
    "gan_generator.load_weights(weights_file('gan_generator.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RiEOmxiLk3St"
   },
   "outputs": [],
   "source": [
    "def resolve_and_plot(lr_image_path):\n",
    "    lr = load_image(lr_image_path)\n",
    "    \n",
    "    pre_sr = resolve_single(pre_generator, lr)\n",
    "    gan_sr = resolve_single(gan_generator, lr)\n",
    "\n",
    "    numpy_array_pre = pre_sr.numpy()\n",
    "    numpy_array_gan = gan_sr.numpy()\n",
    "\n",
    "    image_pre = Image.fromarray(numpy_array_pre)\n",
    "    image_gan = Image.fromarray(numpy_array_gan)\n",
    "\n",
    "    file_name = os.path.basename(lr_image_path)\n",
    "    image_pre.save(os.path.join('/content/drive/MyDrive/output', 'presr'+file_name))\n",
    "    image_gan.save(os.path.join('/content/drive/MyDrive/output', 'gansr'+file_name))\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    images = [lr, pre_sr, gan_sr]\n",
    "    titles = ['LR', 'SR (PRE)', 'SR (GAN)']\n",
    "    positions = [1, 3, 4]\n",
    "    \n",
    "    for i, (img, title, pos) in enumerate(zip(images, titles, positions)):\n",
    "        plt.subplot(2, 2, pos)\n",
    "        plt.imshow(img)\n",
    "        plt.title(title)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTwg03ymlD4Z"
   },
   "outputs": [],
   "source": [
    "# Some examples can be seen in Results\n",
    "resolve_and_plot('/content/drive/MyDrive/faces256/epoch_10_image_1.png')\n",
    "resolve_and_plot('/content/drive/MyDrive/super-resolution-master/demo/0829x4-crop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O45uGjW6ZkAv"
   },
   "outputs": [],
   "source": [
    "# Extract the training loss values from the history object\n",
    "train_loss = history1.history['loss']\n",
    "\n",
    "# Plot the training loss over time\n",
    "plt.plot(train_loss)\n",
    "plt.title('Training Loss of Pretrained Model')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(np.arange(0, len(gen_losses), step=1000))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the training loss over time\n",
    "gen_losses = history2.history['perceptual loss']\n",
    "disc_losses = history2.history['discriminator loss']\n",
    "\n",
    "# plot the losses on the same plot\n",
    "plt.plot(gen_losses, label='Generator Loss')\n",
    "plt.plot(disc_losses, label='Discriminator Loss')\n",
    "plt.title('Training Loss of SRGAN Based on Pretrained Model')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(0, len(gen_losses), step=50))\n",
    "plt.show()\n",
    "\n",
    "# Plot Peak Signal-to-Noise Ratio of pre-trained model\n",
    "z = np.polyfit(range(len(PSNR)), PSNR, 6)\n",
    "p = np.poly1d(z)\n",
    "\n",
    "plt.plot(PSNR)\n",
    "plt.plot(p(range(len(PSNR))), 'r--')\n",
    "plt.title('Peak Signal-to-Noise Ratio')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('PSNR')\n",
    "plt.xticks(np.arange(0, len(PSNR), step=1000))\n",
    "\n",
    "#plt.ylim([20, 50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8woQiJeFz2Jt"
   },
   "outputs": [],
   "source": [
    "# Generate Results\n",
    "file_list = glob.glob(os.path.join('faces256', \"*.png\"))\n",
    "for file_path in file_list:\n",
    "    resolve_and_plot(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "How to change this code to make classes have different forms but same outputs:\n",
    "class DIV2K:\n",
    "    def __init__(self,\n",
    "                 scale=2,\n",
    "                 subset='train',\n",
    "                 downgrade='bicubic',\n",
    "                 images_dir='.div2k/images',\n",
    "                 caches_dir='.div2k/caches'):\n",
    "\n",
    "        self._ntire_2018 = True\n",
    "\n",
    "        _scales = [2, 3, 4, 8]\n",
    "\n",
    "        if scale in _scales:\n",
    "            self.scale = scale\n",
    "        else:\n",
    "            raise ValueError(f'scale must be in ${_scales}')\n",
    "\n",
    "        if subset == 'train':\n",
    "            self.image_ids = range(1, 801)\n",
    "        elif subset == 'valid':\n",
    "            self.image_ids = range(801, 901)\n",
    "        else:\n",
    "            raise ValueError(\"subset must be 'train' or 'valid'\")\n",
    "\n",
    "        _downgrades_a = ['bicubic', 'unknown']\n",
    "        _downgrades_b = ['mild', 'difficult']\n",
    "\n",
    "        if scale == 8 and downgrade != 'bicubic':\n",
    "            raise ValueError(f'scale 8 only allowed for bicubic downgrade')\n",
    "\n",
    "        if downgrade in _downgrades_b and scale != 4:\n",
    "            raise ValueError(f'{downgrade} downgrade requires scale 4')\n",
    "\n",
    "        if downgrade == 'bicubic' and scale == 8:\n",
    "            self.downgrade = 'x8'\n",
    "        elif downgrade in _downgrades_b:\n",
    "            self.downgrade = downgrade\n",
    "        else:\n",
    "            self.downgrade = downgrade\n",
    "            self._ntire_2018 = False\n",
    "\n",
    "        self.subset = subset\n",
    "        self.images_dir = images_dir\n",
    "        self.caches_dir = caches_dir\n",
    "\n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        os.makedirs(caches_dir, exist_ok=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def dataset(self, batch_size=16, repeat_count=None, random_transform=True):\n",
    "        ds = tf.data.Dataset.zip((self.lr_dataset(), self.hr_dataset()))\n",
    "        if random_transform:\n",
    "            ds = ds.map(lambda lr, hr: random_crop(lr, hr, scale=self.scale), num_parallel_calls=AUTOTUNE)\n",
    "            ds = ds.map(random_rotate, num_parallel_calls=AUTOTUNE)\n",
    "            ds = ds.map(random_flip, num_parallel_calls=AUTOTUNE)\n",
    "        ds = ds.batch(batch_size)\n",
    "        ds = ds.repeat(repeat_count)\n",
    "        ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    def hr_dataset(self):\n",
    "        if not os.path.exists(self._hr_images_dir()):\n",
    "            download_archive(self._hr_images_archive(), self.images_dir, extract=True)\n",
    "\n",
    "        ds = self._images_dataset(self._hr_image_files()).cache(self._hr_cache_file())\n",
    "\n",
    "        if not os.path.exists(self._hr_cache_index()):\n",
    "            self._populate_cache(ds, self._hr_cache_file())\n",
    "\n",
    "        return ds\n",
    "\n",
    "    def lr_dataset(self):\n",
    "        if not os.path.exists(self._lr_images_dir()):\n",
    "            download_archive(self._lr_images_archive(), self.images_dir, extract=True)\n",
    "\n",
    "        ds = self._images_dataset(self._lr_image_files()).cache(self._lr_cache_file())\n",
    "\n",
    "        if not os.path.exists(self._lr_cache_index()):\n",
    "            self._populate_cache(ds, self._lr_cache_file())\n",
    "\n",
    "        return ds\n",
    "\n",
    "    def _hr_cache_file(self):\n",
    "        return os.path.join(self.caches_dir, f'DIV2K_{self.subset}_HR.cache')\n",
    "\n",
    "    def _lr_cache_file(self):\n",
    "        return os.path.join(self.caches_dir, f'DIV2K_{self.subset}_LR_{self.downgrade}_X{self.scale}.cache')\n",
    "\n",
    "    def _hr_cache_index(self):\n",
    "        return f'{self._hr_cache_file()}.index'\n",
    "\n",
    "    def _lr_cache_index(self):\n",
    "        return f'{self._lr_cache_file()}.index'\n",
    "\n",
    "    def _hr_image_files(self):\n",
    "        images_dir = self._hr_images_dir()\n",
    "        return [os.path.join(images_dir, f'{image_id:04}.png') for image_id in self.image_ids]\n",
    "\n",
    "    def _lr_image_files(self):\n",
    "        images_dir = self._lr_images_dir()\n",
    "        return [os.path.join(images_dir, self._lr_image_file(image_id)) for image_id in self.image_ids]\n",
    "\n",
    "    def _lr_image_file(self, image_id):\n",
    "        if not self._ntire_2018 or self.scale == 8:\n",
    "            return f'{image_id:04}x{self.scale}.png'\n",
    "        else:\n",
    "            return f'{image_id:04}x{self.scale}{self.downgrade[0]}.png'\n",
    "\n",
    "    def _hr_images_dir(self):\n",
    "        return os.path.join(self.images_dir, f'DIV2K_{self.subset}_HR')\n",
    "\n",
    "    def _lr_images_dir(self):\n",
    "        if self._ntire_2018:\n",
    "            return os.path.join(self.images_dir, f'DIV2K_{self.subset}_LR_{self.downgrade}')\n",
    "        else:\n",
    "            return os.path.join(self.images_dir, f'DIV2K_{self.subset}_LR_{self.downgrade}', f'X{self.scale}')\n",
    "\n",
    "    def _hr_images_archive(self):\n",
    "        return f'DIV2K_{self.subset}_HR.zip'\n",
    "\n",
    "    def _lr_images_archive(self):\n",
    "        if self._ntire_2018:\n",
    "            return f'DIV2K_{self.subset}_LR_{self.downgrade}.zip'\n",
    "        else:\n",
    "            return f'DIV2K_{self.subset}_LR_{self.downgrade}_X{self.scale}.zip'\n",
    "\n",
    "    @staticmethod\n",
    "    def _images_dataset(image_files):\n",
    "        ds = tf.data.Dataset.from_tensor_slices(image_files)\n",
    "        ds = ds.map(tf.io.read_file)\n",
    "        ds = ds.map(lambda x: tf.image.decode_png(x, channels=3), num_parallel_calls=AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    @staticmethod\n",
    "    def _populate_cache(ds, cache_file):\n",
    "        print(f'Caching decoded images in {cache_file} ...')\n",
    "        for _ in ds: pass\n",
    "        print(f'Cached decoded images in {cache_file}.')\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#  Transformations\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "def random_crop(lr_img, hr_img, hr_crop_size=96, scale=2):\n",
    "    lr_crop_size = hr_crop_size // scale\n",
    "    lr_img_shape = tf.shape(lr_img)[:2]\n",
    "\n",
    "    lr_w = tf.random.uniform(shape=(), maxval=lr_img_shape[1] - lr_crop_size + 1, dtype=tf.int32)\n",
    "    lr_h = tf.random.uniform(shape=(), maxval=lr_img_shape[0] - lr_crop_size + 1, dtype=tf.int32)\n",
    "\n",
    "    hr_w = lr_w * scale\n",
    "    hr_h = lr_h * scale\n",
    "\n",
    "    lr_img_cropped = lr_img[lr_h:lr_h + lr_crop_size, lr_w:lr_w + lr_crop_size]\n",
    "    hr_img_cropped = hr_img[hr_h:hr_h + hr_crop_size, hr_w:hr_w + hr_crop_size]\n",
    "\n",
    "    return lr_img_cropped, hr_img_cropped\n",
    "\n",
    "\n",
    "def random_flip(lr_img, hr_img):\n",
    "    rn = tf.random.uniform(shape=(), maxval=1)\n",
    "    return tf.cond(rn < 0.5,\n",
    "                   lambda: (lr_img, hr_img),\n",
    "                   lambda: (tf.image.flip_left_right(lr_img),\n",
    "                            tf.image.flip_left_right(hr_img)))\n",
    "\n",
    "\n",
    "def random_rotate(lr_img, hr_img):\n",
    "    rn = tf.random.uniform(shape=(), maxval=4, dtype=tf.int32)\n",
    "    return tf.image.rot90(lr_img, rn), tf.image.rot90(hr_img, rn)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#  IO\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "def download_archive(file, target_dir, extract=True):\n",
    "    source_url = f'http://data.vision.ee.ethz.ch/cvl/DIV2K/{file}'\n",
    "    target_dir = os.path.abspath(target_dir)\n",
    "    tf.keras.utils.get_file(file, source_url, cache_subdir=target_dir, extract=extract)\n",
    "    os.remove(os.path.join(target_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this cell first if want to train the model and get weigths \n",
    "\n",
    "class DIV2K:\n",
    "    def __init__(self,\n",
    "                 scale=2,\n",
    "                 subset='train',\n",
    "                 downgrade='bicubic',\n",
    "                 images_dir='.div2k/images',\n",
    "                 caches_dir='.div2k/caches'):\n",
    "\n",
    "        self._ntire_2018 = True\n",
    "\n",
    "        _scales = [2, 3, 4, 8]\n",
    "\n",
    "        if scale in _scales:\n",
    "            self.scale = scale\n",
    "        else:\n",
    "            raise ValueError(f'scale must be in ${_scales}')\n",
    "\n",
    "        if subset == 'train':\n",
    "            self.image_ids = range(1, 801)\n",
    "        elif subset == 'valid':\n",
    "            self.image_ids = range(801, 901)\n",
    "        else:\n",
    "            raise ValueError(\"subset must be 'train' or 'valid'\")\n",
    "\n",
    "        _downgrades_a = ['bicubic', 'unknown']\n",
    "        _downgrades_b = ['mild', 'difficult']\n",
    "\n",
    "        if scale == 8 and downgrade != 'bicubic':\n",
    "            raise ValueError(f'scale 8 only allowed for bicubic downgrade')\n",
    "\n",
    "        if downgrade in _downgrades_b and scale != 4:\n",
    "            raise ValueError(f'{downgrade} downgrade requires scale 4')\n",
    "\n",
    "        if downgrade == 'bicubic' and scale == 8:\n",
    "            self.downgrade = 'x8'\n",
    "        elif downgrade in _downgrades_b:\n",
    "            self.downgrade = downgrade\n",
    "        else:\n",
    "            self.downgrade = downgrade\n",
    "            self._ntire_2018 = False\n",
    "\n",
    "        self.subset = subset\n",
    "        self.images_dir = images_dir\n",
    "        self.caches_dir = caches_dir\n",
    "\n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        os.makedirs(caches_dir, exist_ok=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def dataset(self, batch_size=16, repeat_count=None, random_transform=True):\n",
    "        ds = tf.data.Dataset.zip((self.lr_dataset(), self.hr_dataset()))\n",
    "        if random_transform:\n",
    "            ds = ds.map(lambda lr, hr: random_crop(lr, hr, scale=self.scale), num_parallel_calls=AUTOTUNE)\n",
    "            ds = ds.map(random_rotate, num_parallel_calls=AUTOTUNE)\n",
    "            ds = ds.map(random_flip, num_parallel_calls=AUTOTUNE)\n",
    "        ds = ds.batch(batch_size)\n",
    "        ds = ds.repeat(repeat_count)\n",
    "        ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    def hr_dataset(self):\n",
    "        if not os.path.exists(self._hr_images_dir()):\n",
    "            download_archive(self._hr_images_archive(), self.images_dir, extract=True)\n",
    "\n",
    "        ds = self._images_dataset(self._hr_image_files()).cache(self._hr_cache_file())\n",
    "\n",
    "        if not os.path.exists(self._hr_cache_index()):\n",
    "            self._populate_cache(ds, self._hr_cache_file())\n",
    "\n",
    "        return ds\n",
    "\n",
    "    def lr_dataset(self):\n",
    "        if not os.path.exists(self._lr_images_dir()):\n",
    "            download_archive(self._lr_images_archive(), self.images_dir, extract=True)\n",
    "\n",
    "        ds = self._images_dataset(self._lr_image_files()).cache(self._lr_cache_file())\n",
    "\n",
    "        if not os.path.exists(self._lr_cache_index()):\n",
    "            self._populate_cache(ds, self._lr_cache_file())\n",
    "\n",
    "        return ds\n",
    "\n",
    "    def _hr_cache_file(self):\n",
    "        return os.path.join(self.caches_dir, f'DIV2K_{self.subset}_HR.cache')\n",
    "\n",
    "    def _lr_cache_file(self):\n",
    "        return os.path.join(self.caches_dir, f'DIV2K_{self.subset}_LR_{self.downgrade}_X{self.scale}.cache')\n",
    "\n",
    "    def _hr_cache_index(self):\n",
    "        return f'{self._hr_cache_file()}.index'\n",
    "\n",
    "    def _lr_cache_index(self):\n",
    "        return f'{self._lr_cache_file()}.index'\n",
    "\n",
    "    def _hr_image_files(self):\n",
    "        images_dir = self._hr_images_dir()\n",
    "        return [os.path.join(images_dir, f'{image_id:04}.png') for image_id in self.image_ids]\n",
    "\n",
    "    def _lr_image_files(self):\n",
    "        images_dir = self._lr_images_dir()\n",
    "        return [os.path.join(images_dir, self._lr_image_file(image_id)) for image_id in self.image_ids]\n",
    "\n",
    "    def _lr_image_file(self, image_id):\n",
    "        if not self._ntire_2018 or self.scale == 8:\n",
    "            return f'{image_id:04}x{self.scale}.png'\n",
    "        else:\n",
    "            return f'{image_id:04}x{self.scale}{self.downgrade[0]}.png'\n",
    "\n",
    "    def _hr_images_dir(self):\n",
    "        return os.path.join(self.images_dir, f'DIV2K_{self.subset}_HR')\n",
    "\n",
    "    def _lr_images_dir(self):\n",
    "        if self._ntire_2018:\n",
    "            return os.path.join(self.images_dir, f'DIV2K_{self.subset}_LR_{self.downgrade}')\n",
    "        else:\n",
    "            return os.path.join(self.images_dir, f'DIV2K_{self.subset}_LR_{self.downgrade}', f'X{self.scale}')\n",
    "\n",
    "    def _hr_images_archive(self):\n",
    "        return f'DIV2K_{self.subset}_HR.zip'\n",
    "\n",
    "    def _lr_images_archive(self):\n",
    "        if self._ntire_2018:\n",
    "            return f'DIV2K_{self.subset}_LR_{self.downgrade}.zip'\n",
    "        else:\n",
    "            return f'DIV2K_{self.subset}_LR_{self.downgrade}_X{self.scale}.zip'\n",
    "\n",
    "    @staticmethod\n",
    "    def _images_dataset(image_files):\n",
    "        ds = tf.data.Dataset.from_tensor_slices(image_files)\n",
    "        ds = ds.map(tf.io.read_file)\n",
    "        ds = ds.map(lambda x: tf.image.decode_png(x, channels=3), num_parallel_calls=AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    @staticmethod\n",
    "    def _populate_cache(ds, cache_file):\n",
    "        print(f'Caching decoded images in {cache_file} ...')\n",
    "        for _ in ds: pass\n",
    "        print(f'Cached decoded images in {cache_file}.')\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#  Transformations\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "def random_crop(lr_img, hr_img, hr_crop_size=96, scale=2):\n",
    "    lr_crop_size = hr_crop_size // scale\n",
    "    lr_img_shape = tf.shape(lr_img)[:2]\n",
    "\n",
    "    lr_w = tf.random.uniform(shape=(), maxval=lr_img_shape[1] - lr_crop_size + 1, dtype=tf.int32)\n",
    "    lr_h = tf.random.uniform(shape=(), maxval=lr_img_shape[0] - lr_crop_size + 1, dtype=tf.int32)\n",
    "\n",
    "    hr_w = lr_w * scale\n",
    "    hr_h = lr_h * scale\n",
    "\n",
    "    lr_img_cropped = lr_img[lr_h:lr_h + lr_crop_size, lr_w:lr_w + lr_crop_size]\n",
    "    hr_img_cropped = hr_img[hr_h:hr_h + hr_crop_size, hr_w:hr_w + hr_crop_size]\n",
    "\n",
    "    return lr_img_cropped, hr_img_cropped\n",
    "\n",
    "\n",
    "def random_flip(lr_img, hr_img):\n",
    "    rn = tf.random.uniform(shape=(), maxval=1)\n",
    "    return tf.cond(rn < 0.5,\n",
    "                   lambda: (lr_img, hr_img),\n",
    "                   lambda: (tf.image.flip_left_right(lr_img),\n",
    "                            tf.image.flip_left_right(hr_img)))\n",
    "\n",
    "\n",
    "def random_rotate(lr_img, hr_img):\n",
    "    rn = tf.random.uniform(shape=(), maxval=4, dtype=tf.int32)\n",
    "    return tf.image.rot90(lr_img, rn), tf.image.rot90(hr_img, rn)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#  IO\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "def download_archive(file, target_dir, extract=True):\n",
    "    source_url = f'http://data.vision.ee.ethz.ch/cvl/DIV2K/{file}'\n",
    "    target_dir = os.path.abspath(target_dir)\n",
    "    tf.keras.utils.get_file(file, source_url, cache_subdir=target_dir, extract=extract)\n",
    "    os.remove(os.path.join(target_dir, file))\n",
    "    \n",
    "    \n",
    "from tensorflow.keras.layers import Add, Conv2D, Dense, Flatten, Input, LeakyReLU, PReLU, Lambda, BatchNormalization\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "LR_SIZE = 24\n",
    "HR_SIZE = 96\n",
    "\n",
    "\n",
    "def upsample(x_in, num_filters):\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x_in)\n",
    "    x = Lambda(pixel_shuffle(scale=2))(x)\n",
    "    return PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "\n",
    "def res_block(x_in, num_filters, momentum=0.8):\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x_in)\n",
    "    x = BatchNormalization(momentum=momentum)(x)\n",
    "    x = PReLU(shared_axes=[1, 2])(x)\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization(momentum=momentum)(x)\n",
    "    x = Add()([x_in, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def sr_resnet(num_filters=64, num_res_blocks=16):\n",
    "    x_in = Input(shape=(None, None, 3))\n",
    "    x = Lambda(normalize_01)(x_in)\n",
    "\n",
    "    x = Conv2D(num_filters, kernel_size=9, padding='same')(x)\n",
    "    x = x_1 = PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "    for _ in range(num_res_blocks):\n",
    "        x = res_block(x, num_filters)\n",
    "\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x_1, x])\n",
    "\n",
    "    x = upsample(x, num_filters * 4)\n",
    "    x = upsample(x, num_filters * 4)\n",
    "\n",
    "    x = Conv2D(3, kernel_size=9, padding='same', activation='tanh')(x)\n",
    "    x = Lambda(denormalize_m11)(x)\n",
    "\n",
    "    return Model(x_in, x)\n",
    "\n",
    "\n",
    "generator = sr_resnet\n",
    "\n",
    "\n",
    "def discriminator_block(x_in, num_filters, strides=1, batchnorm=True, momentum=0.8):\n",
    "    x = Conv2D(num_filters, kernel_size=3, strides=strides, padding='same')(x_in)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization(momentum=momentum)(x)\n",
    "    return LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\n",
    "def discriminator(num_filters=64):\n",
    "    x_in = Input(shape=(HR_SIZE, HR_SIZE, 3))\n",
    "    x = Lambda(normalize_m11)(x_in)\n",
    "\n",
    "    x = discriminator_block(x, num_filters, batchnorm=False)\n",
    "    x = discriminator_block(x, num_filters, strides=2)\n",
    "\n",
    "    x = discriminator_block(x, num_filters * 2)\n",
    "    x = discriminator_block(x, num_filters * 2, strides=2)\n",
    "\n",
    "    x = discriminator_block(x, num_filters * 4)\n",
    "    x = discriminator_block(x, num_filters * 4, strides=2)\n",
    "\n",
    "    x = discriminator_block(x, num_filters * 8)\n",
    "    x = discriminator_block(x, num_filters * 8, strides=2)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(1024)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(x_in, x)\n",
    "\n",
    "\n",
    "def vgg_22():\n",
    "    return _vgg(5)\n",
    "\n",
    "\n",
    "def vgg_54():\n",
    "    return _vgg(20)\n",
    "\n",
    "\n",
    "def _vgg(output_layer):\n",
    "    vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n",
    "    return Model(vgg.input, vgg.layers[output_layer].output)\n",
    "\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "#from model import evaluate\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 loss,\n",
    "                 learning_rate,\n",
    "                 checkpoint_dir='./ckpt/edsr'):\n",
    "\n",
    "        self.now = None\n",
    "        self.loss = loss\n",
    "        self.checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                              psnr=tf.Variable(-1.0),\n",
    "                                              optimizer=Adam(learning_rate),\n",
    "                                              model=model)\n",
    "        self.checkpoint_manager = tf.train.CheckpointManager(checkpoint=self.checkpoint,\n",
    "                                                             directory=checkpoint_dir,\n",
    "                                                             max_to_keep=3)\n",
    "\n",
    "        self.restore()\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self.checkpoint.model\n",
    "\n",
    "    def train(self, train_dataset, valid_dataset, steps, evaluate_every=1000, save_best_only=False):\n",
    "        loss_mean = Mean()\n",
    "\n",
    "        ckpt_mgr = self.checkpoint_manager\n",
    "        ckpt = self.checkpoint\n",
    "\n",
    "        self.now = time.perf_counter()\n",
    "\n",
    "        for lr, hr in train_dataset.take(steps - ckpt.step.numpy()):\n",
    "            ckpt.step.assign_add(1)\n",
    "            step = ckpt.step.numpy()\n",
    "\n",
    "            loss = self.train_step(lr, hr)\n",
    "            loss_mean(loss)\n",
    "\n",
    "            if step % evaluate_every == 0:\n",
    "                loss_value = loss_mean.result()\n",
    "                loss_mean.reset_states()\n",
    "\n",
    "                # Compute PSNR on validation dataset\n",
    "                psnr_value = self.evaluate(valid_dataset)\n",
    "\n",
    "                duration = time.perf_counter() - self.now\n",
    "                print(f'{step}/{steps}: loss = {loss_value.numpy():.3f}, PSNR = {psnr_value.numpy():3f} ({duration:.2f}s)')\n",
    "\n",
    "                if save_best_only and psnr_value <= ckpt.psnr:\n",
    "                    self.now = time.perf_counter()\n",
    "                    # skip saving checkpoint, no PSNR improvement\n",
    "                    continue\n",
    "\n",
    "                ckpt.psnr = psnr_value\n",
    "                ckpt_mgr.save()\n",
    "\n",
    "                self.now = time.perf_counter()\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, lr, hr):\n",
    "        with tf.GradientTape() as tape:\n",
    "            lr = tf.cast(lr, tf.float32)\n",
    "            hr = tf.cast(hr, tf.float32)\n",
    "\n",
    "            sr = self.checkpoint.model(lr, training=True)\n",
    "            loss_value = self.loss(hr, sr)\n",
    "\n",
    "        gradients = tape.gradient(loss_value, self.checkpoint.model.trainable_variables)\n",
    "        self.checkpoint.optimizer.apply_gradients(zip(gradients, self.checkpoint.model.trainable_variables))\n",
    "\n",
    "        return loss_value\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        return evaluate(self.checkpoint.model, dataset)\n",
    "\n",
    "    def restore(self):\n",
    "        if self.checkpoint_manager.latest_checkpoint:\n",
    "            self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
    "            print(f'Model restored from checkpoint at step {self.checkpoint.step.numpy()}.')\n",
    "\n",
    "\n",
    "class EdsrTrainer(Trainer):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 checkpoint_dir,\n",
    "                 learning_rate=PiecewiseConstantDecay(boundaries=[200000], values=[1e-4, 5e-5])):\n",
    "        super().__init__(model, loss=MeanAbsoluteError(), learning_rate=learning_rate, checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "    def train(self, train_dataset, valid_dataset, steps=300000, evaluate_every=1000, save_best_only=True):\n",
    "        super().train(train_dataset, valid_dataset, steps, evaluate_every, save_best_only)\n",
    "\n",
    "\n",
    "class WdsrTrainer(Trainer):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 checkpoint_dir,\n",
    "                 learning_rate=PiecewiseConstantDecay(boundaries=[200000], values=[1e-3, 5e-4])):\n",
    "        super().__init__(model, loss=MeanAbsoluteError(), learning_rate=learning_rate, checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "    def train(self, train_dataset, valid_dataset, steps=300000, evaluate_every=1000, save_best_only=True):\n",
    "        super().train(train_dataset, valid_dataset, steps, evaluate_every, save_best_only)\n",
    "\n",
    "\n",
    "class SrganGeneratorTrainer(Trainer):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 checkpoint_dir,\n",
    "                 learning_rate=1e-4):\n",
    "        super().__init__(model, loss=MeanSquaredError(), learning_rate=learning_rate, checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "    def train(self, train_dataset, valid_dataset, steps=1000000, evaluate_every=1000, save_best_only=True):\n",
    "        super().train(train_dataset, valid_dataset, steps, evaluate_every, save_best_only)\n",
    "\n",
    "\n",
    "class SrganTrainer:\n",
    "    #\n",
    "    # TODO: model and optimizer checkpoints\n",
    "    #\n",
    "    def __init__(self,\n",
    "                 generator,\n",
    "                 discriminator,\n",
    "                 content_loss='VGG54',\n",
    "                 learning_rate=PiecewiseConstantDecay(boundaries=[100000], values=[1e-4, 1e-5])):\n",
    "\n",
    "        if content_loss == 'VGG22':\n",
    "            self.vgg = vgg_22()\n",
    "        elif content_loss == 'VGG54':\n",
    "            self.vgg = vgg_54()\n",
    "        else:\n",
    "            raise ValueError(\"content_loss must be either 'VGG22' or 'VGG54'\")\n",
    "\n",
    "        self.content_loss = content_loss\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.generator_optimizer = Adam(learning_rate=learning_rate)\n",
    "        self.discriminator_optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "        self.binary_cross_entropy = BinaryCrossentropy(from_logits=False)\n",
    "        self.mean_squared_error = MeanSquaredError()\n",
    "\n",
    "    def train(self, train_dataset, steps=200000):\n",
    "        pls_metric = Mean()\n",
    "        dls_metric = Mean()\n",
    "        step = 0\n",
    "\n",
    "        for lr, hr in train_dataset.take(steps):\n",
    "            step += 1\n",
    "\n",
    "            pl, dl = self.train_step(lr, hr)\n",
    "            pls_metric(pl)\n",
    "            dls_metric(dl)\n",
    "\n",
    "            if step % 50 == 0:\n",
    "                print(f'{step}/{steps}, perceptual loss = {pls_metric.result():.4f}, discriminator loss = {dls_metric.result():.4f}')\n",
    "                pls_metric.reset_states()\n",
    "                dls_metric.reset_states()\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, lr, hr):\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            lr = tf.cast(lr, tf.float32)\n",
    "            hr = tf.cast(hr, tf.float32)\n",
    "\n",
    "            sr = self.generator(lr, training=True)\n",
    "\n",
    "            hr_output = self.discriminator(hr, training=True)\n",
    "            sr_output = self.discriminator(sr, training=True)\n",
    "\n",
    "            con_loss = self._content_loss(hr, sr)\n",
    "            gen_loss = self._generator_loss(sr_output)\n",
    "            perc_loss = con_loss + 0.001 * gen_loss\n",
    "            disc_loss = self._discriminator_loss(hr_output, sr_output)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(perc_loss, self.generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "        self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "        self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "\n",
    "        return perc_loss, disc_loss\n",
    "\n",
    "    @tf.function\n",
    "    def _content_loss(self, hr, sr):\n",
    "        sr = preprocess_input(sr)\n",
    "        hr = preprocess_input(hr)\n",
    "        sr_features = self.vgg(sr) / 12.75\n",
    "        hr_features = self.vgg(hr) / 12.75\n",
    "        return self.mean_squared_error(hr_features, sr_features)\n",
    "\n",
    "    def _generator_loss(self, sr_out):\n",
    "        return self.binary_cross_entropy(tf.ones_like(sr_out), sr_out)\n",
    "\n",
    "    def _discriminator_loss(self, hr_out, sr_out):\n",
    "        hr_loss = self.binary_cross_entropy(tf.ones_like(hr_out), hr_out)\n",
    "        sr_loss = self.binary_cross_entropy(tf.zeros_like(sr_out), sr_out)\n",
    "        return hr_loss + sr_loss\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "DIV2K_RGB_MEAN = np.array([0.4488, 0.4371, 0.4040]) * 255\n",
    "\n",
    "\n",
    "def resolve_single(model, lr):\n",
    "    return resolve(model, tf.expand_dims(lr, axis=0))[0]\n",
    "\n",
    "\n",
    "def resolve(model, lr_batch):\n",
    "    lr_batch = tf.cast(lr_batch, tf.float32)\n",
    "    sr_batch = model(lr_batch)\n",
    "    sr_batch = tf.clip_by_value(sr_batch, 0, 255)\n",
    "    sr_batch = tf.round(sr_batch)\n",
    "    sr_batch = tf.cast(sr_batch, tf.uint8)\n",
    "    return sr_batch\n",
    "\n",
    "\n",
    "def evaluate(model, dataset):\n",
    "    psnr_values = []\n",
    "    for lr, hr in dataset:\n",
    "        sr = resolve(model, lr)\n",
    "        psnr_value = psnr(hr, sr)[0]\n",
    "        psnr_values.append(psnr_value)\n",
    "    return tf.reduce_mean(psnr_values)\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "#  Normalization\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "def normalize(x, rgb_mean=DIV2K_RGB_MEAN):\n",
    "    return (x - rgb_mean) / 127.5\n",
    "\n",
    "\n",
    "def denormalize(x, rgb_mean=DIV2K_RGB_MEAN):\n",
    "    return x * 127.5 + rgb_mean\n",
    "\n",
    "\n",
    "def normalize_01(x):\n",
    "    \"\"\"Normalizes RGB images to [0, 1].\"\"\"\n",
    "    return x / 255.0\n",
    "\n",
    "\n",
    "def normalize_m11(x):\n",
    "    \"\"\"Normalizes RGB images to [-1, 1].\"\"\"\n",
    "    return x / 127.5 - 1\n",
    "\n",
    "\n",
    "def denormalize_m11(x):\n",
    "    \"\"\"Inverse of normalize_m11.\"\"\"\n",
    "    return (x + 1) * 127.5\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "#  Metrics\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "def psnr(x1, x2):\n",
    "    return tf.image.psnr(x1, x2, max_val=255)\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "#  See https://arxiv.org/abs/1609.05158\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "def pixel_shuffle(scale):\n",
    "    return lambda x: tf.nn.depth_to_space(x, scale)\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "def plot_sample(lr, sr):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    images = [lr, sr]\n",
    "    titles = ['LR', f'SR (x{sr.shape[0] // lr.shape[0]})']\n",
    "\n",
    "    for i, (img, title) in enumerate(zip(images, titles)):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(title)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
